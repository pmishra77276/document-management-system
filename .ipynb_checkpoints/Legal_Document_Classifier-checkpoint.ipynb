{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e446ef-fbf8-4c27-9dd9-0bd79e028d53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1.st model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5f781-c277-4486-8951-a24bd58f5e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFacePipeline\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM,BitsAndBytesConfig,StoppingCriteria, StoppingCriteriaList\n",
    "import torch\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b9a9a10-746e-4826-b10d-20d842ccae2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 7.78 GiB of which 18.62 MiB is free. Process 1482 has 124.41 MiB memory in use. Including non-PyTorch memory, this process has 7.63 GiB memory in use. Of the allocated memory 7.45 GiB is allocated by PyTorch, and 117.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 115\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# docs=loading_pdf()\u001b[39;00m\n\u001b[1;32m    114\u001b[0m docs\u001b[38;5;241m=\u001b[39mloading_pdf1(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/pa2/ml/Document-Classification/files/US7054127.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m db\u001b[38;5;241m=\u001b[39m\u001b[43mfaiss1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 33\u001b[0m, in \u001b[0;36mfaiss1\u001b[0;34m(docs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfaiss1\u001b[39m(docs):\n\u001b[1;32m     30\u001b[0m     model\u001b[38;5;241m=\u001b[39mHuggingFaceEmbeddings(\n\u001b[1;32m     31\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers/all-mpnet-base-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m     )\n\u001b[0;32m---> 33\u001b[0m     db\u001b[38;5;241m=\u001b[39m\u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m db\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/langchain_core/vectorstores/base.py:844\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[1;32m    842\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[0;32m--> 844\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:1043\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1024\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \n\u001b[1;32m   1027\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[1;32m   1045\u001b[0m         texts,\n\u001b[1;32m   1046\u001b[0m         embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1051\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/langchain_huggingface/embeddings/huggingface.py:85\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     83\u001b[0m     sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer\u001b[38;5;241m.\u001b[39mstop_multi_process_pool(pool)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embeddings, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected embeddings to be a Tensor or a numpy array, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:623\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 623\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    625\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:690\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    689\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:442\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m trans_features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    437\u001b[0m     key: value\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    440\u001b[0m }\n\u001b[0;32m--> 442\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# If the AutoModel is wrapped with a PeftModelForFeatureExtraction, then it may have added virtual tokens\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# We need to extend the attention mask to include these virtual tokens, or the pooling will fail\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:544\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    543\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds)\n\u001b[0;32m--> 544\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    553\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:334\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    332\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 334\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:293\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    286\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    292\u001b[0m ):\n\u001b[0;32m--> 293\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    301\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:234\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    227\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(self_outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m hidden_states)\n\u001b[1;32m    242\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:188\u001b[0m, in \u001b[0;36mMPNetSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     attention_probs \u001b[38;5;241m=\u001b[39m attention_probs \u001b[38;5;241m*\u001b[39m head_mask\n\u001b[0;32m--> 188\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m c \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    191\u001b[0m new_c_shape \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size,)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 7.78 GiB of which 18.62 MiB is free. Process 1482 has 124.41 MiB memory in use. Including non-PyTorch memory, this process has 7.63 GiB memory in use. Of the allocated memory 7.45 GiB is allocated by PyTorch, and 117.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "class Stream(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, stop_token_id=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stop_token_id = stop_token_id\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        new_token_id = input_ids[0, -1].item()\n",
    "        if self.stop_token_id is not None and new_token_id == self.stop_token_id:\n",
    "            return True\n",
    "        token_text = self.tokenizer.decode([new_token_id], skip_special_tokens=False)\n",
    "        print(token_text, end=\"\", flush=True)\n",
    "        return False\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def loading_pdf(path=\"/home/pa2/ml/Document-Classification/files/1_D:\\BPL\\BLS\\Document\\Arbitration Award of Zostel Hospitality relied upon by the Claimant.txt\"):\n",
    "    \"\"\"Loads a text file and splits it into chunks.\"\"\"\n",
    "    loader = TextLoader(path, encoding=\"utf-8\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    \n",
    "    return docs\n",
    "    \n",
    "def faiss1(docs):\n",
    "    model=HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "    )\n",
    "    db=FAISS.from_documents(docs,model)\n",
    "    return db\n",
    "def model1(context,query,chat,model,tokenizer,maxlen=3000):\n",
    "    \n",
    "    message = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"You are a legal assistant trained to classify legal documents with zero tolerance for guessing. You will follow the rules below without exception:\n",
    "\n",
    "RULES:\n",
    "1. Do NOT make assumptions or use external knowledge.\n",
    "2. You MUST only use the words or phrases found directly in the context.\n",
    "3. You MUST explain your classification using legal terminology that appears in the context.\n",
    "4. You MUST follow the exact output format shown below.\n",
    "5. You MUST return one and only one legal category from the provided list.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "\n",
    "<think>\n",
    "Step-by-step reasoning using ONLY the context. Refer to legal phrases or structure. Do not go outside the context or speculate.\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "Choose ONLY ONE from this list (copy-paste one line only):\n",
    "\n",
    "1. Contractual  \n",
    "2. Regulatory and Compliance  \n",
    "3. Intellectual Property Rights (IPR)  \n",
    "4. Litigation and Dispute  \n",
    "5. Property and Real Estate  \n",
    "6. Corporate and Governance  \n",
    "7. Employment and Human Resources (HR)  \n",
    "8. Finance and Banking  \n",
    "9. Government and Public Laws  \n",
    "10. Personal and Civil Legal Documents  \n",
    "11. Others\n",
    "\n",
    "The answer must exactly match one of the above. Do NOT add anything else.\n",
    "</answer>\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: What is the correct legal category for this document?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    }]\n",
    "\n",
    "    prompt=tokenizer.apply_chat_template(message,tokenize=False)\n",
    "    input_ids=tokenizer(prompt,return_tensors='pt').to(\"cuda\")\n",
    "    stopping_criteria = StoppingCriteriaList([Stream(tokenizer)])\n",
    "    with torch.no_grad():\n",
    "        response=model.generate(input_ids=input_ids['input_ids'],\n",
    "                                attention_mask=input_ids['attention_mask'],\n",
    "                                stopping_criteria=stopping_criteria,\n",
    "                                max_new_tokens=maxlen,\n",
    "                                use_cache=True,\n",
    "                               temperature=0.1,)\n",
    "    answer=tokenizer.decode(response[0])\n",
    "    print()\n",
    "    return answer\n",
    "def loading_pdf1(path):\n",
    "    \"\"\"Loads a PDF or text file and splits it into chunks.\"\"\"\n",
    "    if path.endswith(\".txt\"):\n",
    "        loader = TextLoader(path, encoding=\"utf-8\")\n",
    "    elif path.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Only .txt and .pdf are supported.\")\n",
    "\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    return docs\n",
    "# docs=loading_pdf()\n",
    "docs=loading_pdf1(\"/home/pa2/ml/Document-Classification/files/US7054127.pdf\")\n",
    "db=faiss1(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3df9f1-6416-4ac7-80f7-885a8b05aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B')\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4'\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B',\n",
    "    device_map='cuda',\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3601ee57-7e11-46e7-9e65-7531e35f5f06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options:\n",
      "1. Contractual\n",
      "2. Regulatory and Compliance\n",
      "3. Intellectual Property Rights (IPR)\n",
      "4. Litigation and Dispute\n",
      "5. Property and Real Estate\n",
      "6. Corporate and Governance\n",
      "7. Employment and Human Resources (HR)\n",
      "8. Finance and Banking\n",
      "9. Government and Public Laws\n",
      "10. Personal and Civil Legal Documents\n",
      "11. Others\n",
      "\n",
      "Answer: Personal and Civil Legal Documents<｜end▁of▁sentence｜>\n",
      "\n",
      "[Model Output]:\n",
      " <｜begin▁of▁sentence｜><｜begin▁of▁sentence｜><｜User｜>You are a legal assistant trained to classify legal documents with zero tolerance for guessing. You will follow the rules below without exception:\n",
      "\n",
      "RULES:\n",
      "1. Do NOT make assumptions or use external knowledge.\n",
      "2. You MUST only use the words or phrases found directly in the context.\n",
      "3. You MUST explain your classification using legal terminology that appears in the context.\n",
      "4. You MUST follow the exact output format shown below.\n",
      "5. You MUST return one and only one legal category from the provided list.\n",
      "\n",
      "OUTPUT FORMAT:\n",
      "\n",
      "<think>\n",
      "Step-by-step reasoning using ONLY the context. Refer to legal phrases or structure. Do not go outside the context or speculate.\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "Choose ONLY ONE from this list (copy-paste one line only):\n",
      "\n",
      "1. Contractual  \n",
      "2. Regulatory and Compliance  \n",
      "3. Intellectual Property Rights (IPR)  \n",
      "4. Litigation and Dispute  \n",
      "5. Property and Real Estate  \n",
      "6. Corporate and Governance  \n",
      "7. Employment and Human Resources (HR)  \n",
      "8. Finance and Banking  \n",
      "9. Government and Public Laws  \n",
      "10. Personal and Civil Legal Documents  \n",
      "11. Others\n",
      "\n",
      "The answer must exactly match one of the above. Do NOT add anything else.\n",
      "</answer>\n",
      "\n",
      "<context>\n",
      "US 7,054,127 B1 Sheet 4 of 6 May 30, 2006 U.S. Patent \n",
      " 00A ?õ? „LITIO?HIO OINON LOETE\n",
      "\n",
      "US 7,054,127 B1 \n",
      " LITTO?-||O OINOHLOETE \n",
      " U.S. Patent\n",
      "\n",
      "US 7,054,127 B1 Sheet 1 of 6 May 30, 2006 U.S. Patent \n",
      " N-661 \n",
      " |\n",
      "\n",
      "US 7.054,127 B1 \n",
      " UTZ Cl}}\\/Og LITTONIO \n",
      " Sheet 3 of 6 May 30, 2006 U.S. Patent\n",
      "\n",
      "the term of this Primary Examiner Phuong T. Vu patent is extended or adjusted under 35 Assistant Examiner—Ann Hoang U.S.C. 154(b) by 310 days. (74) Attorney, Agent, or Firm BainwoodHuang; David E. Huang, Esq. (21) Appl. No.: 10/464,686 (57) ABSTRACT (22) Filed: Jun. 18, 2003 A cable device includes an integrated Surge protection (51) Int. Cl. circuit. In the event that, communication signals conveyed HOIC 7/2 (2006.01) by the cable include (potentially damaging) transient Volt HO2H IMO (2006.01) ages, the Surge protection circuit integrated in the cable HO2H IM04 (2006.01) Suppresses the transient Voltages at a distance from a cor HO2H 3/22 (2006.01) responding electronic circuit to which the cable is attached. HO2H 9/06 (2006.01) Consequently, potentially damaging Voltage transients (52) U.S. Cl. ...................... 361/119, 361/911; 361/91.7 imparted on the communication signals are clamped before (58) Field of Classification Search ................ 361/119, reaching potentially\n",
      "</context>\n",
      "\n",
      "Question: What is the correct legal category for this document?\n",
      "\n",
      "Options:\n",
      "1. Contractual\n",
      "2. Regulatory and Compliance\n",
      "3. Intellectual Property Rights (IPR)\n",
      "4. Litigation and Dispute\n",
      "5. Property and Real Estate\n",
      "6. Corporate and Governance\n",
      "7. Employment and Human Resources (HR)\n",
      "8. Finance and Banking\n",
      "9. Government and Public Laws\n",
      "10. Personal and Civil Legal Documents\n",
      "11. Others\n",
      "\n",
      "Answer: Personal and Civil Legal Documents<｜end▁of▁sentence｜> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    chat = \"\"\n",
    "    \n",
    "    while True:\n",
    "        query = \"Identify the type of this legal document based on its content. Return only the most informative parts for classification like headers, definitions, or legal phrases.\"\n",
    "\n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Thanks for using the classifier!\")\n",
    "            break\n",
    "        similar_chunks = db.similarity_search(query, k=5)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in similar_chunks])\n",
    "        try:\n",
    "            response = model1(context=context, query=query, chat=chat, model=model, tokenizer=tokenizer,maxlen=2048)\n",
    "            print(\"\\n[Model Output]:\\n\", response.strip(), \"\\n\")\n",
    "            chat = response\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error during inference]: {e}\")\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a912c29-6a40-4182-ab42-fb1f0a41fbba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Using LLAMA 3 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8d661f-5fe9-43de-9fe2-87c8f106ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFacePipeline\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM,BitsAndBytesConfig,StoppingCriteria, StoppingCriteriaList\n",
    "import torch\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db54d3c4-1baa-4ec9-8479-25a425541564",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stream(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, stop_token_id=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stop_token_id = stop_token_id\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        new_token_id = input_ids[0, -1].item()\n",
    "        if self.stop_token_id is not None and new_token_id == self.stop_token_id:\n",
    "            return True\n",
    "        token_text = self.tokenizer.decode([new_token_id], skip_special_tokens=False)\n",
    "        print(token_text, end=\"\", flush=True)\n",
    "        return False\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def loading_pdf(path=\"/home/pa2/ml/Document-Classification/files/1_D:\\BPL\\BLS\\Document\\Arbitration Award of Zostel Hospitality relied upon by the Claimant.txt\"):\n",
    "    \"\"\"Loads a text file and splits it into chunks.\"\"\"\n",
    "    loader = TextLoader(path, encoding=\"utf-8\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    \n",
    "    return docs\n",
    "    \n",
    "def faiss1(docs):\n",
    "    model=HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "    )\n",
    "    db=FAISS.from_documents(docs,model)\n",
    "    return db\n",
    "def model1(context,query,chat,model,tokenizer,maxlen=3000):\n",
    "    \n",
    "    message = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"You are a legal assistant trained to classify legal documents with zero tolerance for guessing. You will follow the rules below without exception:\n",
    "\n",
    "RULES:\n",
    "1. Do NOT make assumptions or use external knowledge.\n",
    "2. You MUST only use the words or phrases found directly in the context.\n",
    "3. You MUST explain your classification using legal terminology that appears in the context.\n",
    "4. You MUST follow the exact output format shown below.\n",
    "5. You MUST return one and only one legal category from the provided list.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "\n",
    "<think>\n",
    "Step-by-step reasoning using ONLY the context. Refer to legal phrases or structure. Do not go outside the context or speculate.\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "Choose ONLY ONE from this list (copy-paste one line only):\n",
    "\n",
    "1. Contractual  \n",
    "2. Regulatory and Compliance  \n",
    "3. Intellectual Property Rights (IPR)  \n",
    "4. Litigation and Dispute  \n",
    "5. Property and Real Estate  \n",
    "6. Corporate and Governance  \n",
    "7. Employment and Human Resources (HR)  \n",
    "8. Finance and Banking  \n",
    "9. Government and Public Laws  \n",
    "10. Personal and Civil Legal Documents  \n",
    "11. Others\n",
    "\n",
    "The answer must exactly match one of the above. Do NOT add anything else.\n",
    "</answer>\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: What is the correct legal category for this document?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    }]\n",
    "\n",
    "    prompt=tokenizer.apply_chat_template(message,tokenize=False)\n",
    "    input_ids=tokenizer(prompt,return_tensors='pt').to(\"cuda\")\n",
    "    stopping_criteria = StoppingCriteriaList([Stream(tokenizer)])\n",
    "    with torch.no_grad():\n",
    "        response=model.generate(input_ids=input_ids['input_ids'],\n",
    "                                attention_mask=input_ids['attention_mask'],\n",
    "                                stopping_criteria=stopping_criteria,\n",
    "                                max_new_tokens=maxlen,\n",
    "                                use_cache=True,\n",
    "                               temperature=0.1,)\n",
    "    answer=tokenizer.decode(response[0])\n",
    "    print()\n",
    "    return answer\n",
    "def loading_pdf1(path):\n",
    "    \"\"\"Loads a PDF or text file and splits it into chunks.\"\"\"\n",
    "    if path.endswith(\".txt\"):\n",
    "        loader = TextLoader(path, encoding=\"utf-8\")\n",
    "    elif path.lower().endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Only .txt and .pdf are supported.\")\n",
    "\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    return docs\n",
    "# docs=loading_pdf()\n",
    "docs=loading_pdf1(\"/home/pa2/ml/Document-Classification/files/US7054127.pdf\")\n",
    "db=faiss1(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d758b3b4-82b5-460a-a1cb-b01f0b91ec68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7637d8d229f48bc9eef7924a1e646b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4'\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    device_map='cuda',\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27fd62a0-a7ac-4111-bdda-c222c2f1a93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<think>\n",
      "The document is a patent application or patent, as indicated by the \"U.S. Patent\" label and the presence of a patent number (7,054,127 B1). The content describes a technical invention, including a detailed explanation of the invention, its purpose, and its classification under the International Classification (Int. Cl.) and U.S. Classification (U.S. Cl.). The document also mentions the Primary Examiner and Assistant Examiner, which are roles associated with the patent examination process. Furthermore, the document includes a notice of extension or adjustment of the patent term under 35 U.S.C. 154(b). These elements are characteristic of a patent document.\n",
      "\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "1. Contractual  \n",
      "</answer><|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    chat = \"\"\n",
    "    \n",
    "    while True:\n",
    "        query = \"Identify the type of this legal document based on its content. Return only the most informative parts for classification like headers, definitions, or legal phrases.\"\n",
    "\n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Thanks for using the classifier!\")\n",
    "            break\n",
    "        similar_chunks = db.similarity_search(query, k=5)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in similar_chunks])\n",
    "        try:\n",
    "            response = model1(context=context, query=query, chat=chat, model=model, tokenizer=tokenizer,maxlen=2048)\n",
    "            chat = response\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error during inference]: {e}\")\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429e34d-38dc-4f8f-8747-fada55c8a00a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LLama 3.2 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40d46fd-40f5-4af2-a5d5-5e4f1766ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFacePipeline\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM,BitsAndBytesConfig,StoppingCriteria, StoppingCriteriaList\n",
    "import torch\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2beaf0c9-1d6c-4d22-9cad-80d6c8b53acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stream(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, stop_token_id=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stop_token_id = stop_token_id\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        new_token_id = input_ids[0, -1].item()\n",
    "        if self.stop_token_id is not None and new_token_id == self.stop_token_id:\n",
    "            return True\n",
    "        token_text = self.tokenizer.decode([new_token_id], skip_special_tokens=False)\n",
    "        print(token_text, end=\"\", flush=True)\n",
    "        return False\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def loading_pdf(path=\"/home/pa2/ml/Document-Classification/files/1_D:\\BPL\\BLS\\Document\\Arbitration Award of Zostel Hospitality relied upon by the Claimant.txt\"):\n",
    "    \"\"\"Loads a text file and splits it into chunks.\"\"\"\n",
    "    loader = TextLoader(path, encoding=\"utf-8\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    \n",
    "    return docs\n",
    "    \n",
    "def faiss1(docs):\n",
    "    model=HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "    )\n",
    "    db=FAISS.from_documents(docs,model)\n",
    "    return db\n",
    "def model1(context,query,chat,model,tokenizer,maxlen=3000):\n",
    "    \n",
    "    message = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"You are a legal assistant trained to classify legal documents with zero tolerance for guessing. You must follow the rules below strictly:\n",
    "\n",
    "RULES:\n",
    "1. Do NOT make assumptions or use external knowledge.\n",
    "2. ONLY use exact words, legal terms, and structures from the given context.\n",
    "3. You MUST explain your classification using legal terminology from the context.\n",
    "4. You MUST follow the exact output format below.\n",
    "5. Return one and only one category from the list below.\n",
    "\n",
    "LEGAL CATEGORIES with EXAMPLES:\n",
    "\n",
    "1. Contractual – (e.g., B2B agreements, purchase orders, NDAs, service contracts)  \n",
    "2. Regulatory and Compliance – (e.g., compliance reports, internal audits, regulatory filings)  \n",
    "3. Intellectual Property Rights (IPR) – (e.g., patents, trademarks, copyrights, design rights, trade secrets)  \n",
    "4. Litigation and Dispute – (e.g., court filings, legal notices, arbitration claims, judgments)  \n",
    "5. Property and Real Estate – (e.g., lease agreements, sale deeds, land registration, rent contracts)  \n",
    "6. Corporate and Governance – (e.g., company formation docs, resolutions, board meeting records, annual filings)  \n",
    "7. Employment and Human Resources (HR) – (e.g., employee contracts, HR policies, separation letters)  \n",
    "8. Finance and Banking – (e.g., loan agreements, collateral deeds, investment deals, bank guarantees)  \n",
    "9. Government and Public Laws – (e.g., RTI responses, government licenses, public notices, certificates)  \n",
    "10. Personal and Civil Legal Documents – (e.g., ID proofs, affidavits, marriage/divorce documents, family law papers)  \n",
    "11. Others – (Only if no other category fits)\n",
    "\n",
    "---\n",
    "MANDATORY RULE MUST FOLLOW :-\n",
    "-> **PROPERLY SHOW ALL THE STEPS IN <think> SECTION** (MANDATORY)\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "---\n",
    "\n",
    "<think>Steps\n",
    "\n",
    "Step 1: Extracted Legal Keywords →  \n",
    "[List all legal terms, phrases, and document structures found directly in the context.]\n",
    "\n",
    "Step 2: Short Legal Summary →  \n",
    "[Summarize the context in 2–3 lines using legal wording, sticking strictly to the content.]\n",
    "\n",
    "Step 3: Multi-Angle Rethinking →  \n",
    "[Restate the summary from multiple angles: formal, casual, detailed, abstract, technical.]\n",
    "\n",
    "Step 4: Category Matching →  \n",
    "[Compare summary + keywords against each category. Write your thought process for every match or mismatch.]\n",
    "\n",
    "Step 5: Eliminate Unrelated Categories →  \n",
    "[List all categories that clearly do NOT apply and briefly explain why.]\n",
    "\n",
    "Step 6: Deep Legal Reasoning →  \n",
    "[Based on the remaining options, explain in detail why one specific category is the strongest fit using legal logic.]\n",
    "\n",
    "Step 7: Final Justification →  \n",
    "[Final 1-2 lines defending your classification using exact phrases or structure from the context.]\n",
    "\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "Choose ONLY ONE from this list (copy-paste one line only):\n",
    "\n",
    "1. Contractual  \n",
    "2. Regulatory and Compliance  \n",
    "3. Intellectual Property Rights (IPR)  \n",
    "4. Litigation and Dispute  \n",
    "5. Property and Real Estate  \n",
    "6. Corporate and Governance  \n",
    "7. Employment and Human Resources (HR)  \n",
    "8. Finance and Banking  \n",
    "9. Government and Public Laws  \n",
    "10. Personal and Civil Legal Documents  \n",
    "11. Others\n",
    "</answer>\n",
    "\n",
    "\n",
    "Question: What is the correct legal category for this document?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    }]\n",
    "\n",
    "    prompt=tokenizer.apply_chat_template(message,tokenize=False)\n",
    "    input_ids=tokenizer(prompt,return_tensors='pt').to(\"cuda\")\n",
    "    stopping_criteria = StoppingCriteriaList([Stream(tokenizer)])\n",
    "    with torch.no_grad():\n",
    "        response=model.generate(input_ids=input_ids['input_ids'],\n",
    "                                attention_mask=input_ids['attention_mask'],\n",
    "                                stopping_criteria=stopping_criteria,\n",
    "                                max_new_tokens=maxlen,\n",
    "                                use_cache=True,\n",
    "                               temperature=0.1,)\n",
    "    answer=tokenizer.decode(response[0])\n",
    "    print()\n",
    "    return answer\n",
    "def loading_pdf1(path):\n",
    "    \"\"\"Loads a PDF or text file and splits it into chunks.\"\"\"\n",
    "    if path.endswith(\".txt\"):\n",
    "        loader = TextLoader(path, encoding=\"utf-8\")\n",
    "    elif path.lower().endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Only .txt and .pdf are supported.\")\n",
    "\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    return docs\n",
    "# docs=loading_pdf()\n",
    "docs=loading_pdf1(\"/home/pa2/ml/Document-Classification/Dataset/Litigation and Dispute/Master_G_Through_Legal_Guardian_Anr_vs_State_Nct_Of_Delhi_Home_Department_on_2_April_2025.PDF\")\n",
    "db=faiss1(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ecd1490-447a-4a59-8549-de69d9ac6bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc640da41256446daf7ec40fd461b395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-3B-Instruct')\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4'\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'meta-llama/Llama-3.2-3B-Instruct',\n",
    "    device_map='cuda',\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c32c901-3cc9-4110-83f0-db08bc0cf297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<answer>\n",
      "1. Contractual<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    chat = \"\"\n",
    "    \n",
    "    while True:\n",
    "        query = \"\"\"Retrieve the most informative sections of this legal document that can help determine its legal classification. Prioritize segments containing legal terms, section headings, clauses, named parties, obligations, dates, and governing laws. Specifically look for any signs related to:\n",
    "\n",
    "1. Contractual – references to B2B or B2C agreements, terms and conditions, service-level agreements, non-disclosure agreements, etc.\n",
    "2. Regulatory and Compliance – internal audit language, compliance obligations, policy enforcement, external submissions to government bodies.\n",
    "3. Intellectual Property Rights (IPR) – mentions of patents, copyrights, trademarks, trade secrets, licenses, or intellectual asset ownership.\n",
    "4. Litigation and Dispute – phrases like \"court order\", \"petition\", \"judgment\", \"arbitration\", \"claim\", or \"legal dispute\".\n",
    "5. Property and Real Estate – lease terms, ownership transfers, land records, mortgage agreements, property deeds.\n",
    "6. Corporate and Governance – company founding documents, board resolutions, shareholder agreements, filings, annual reports.\n",
    "7. Employment and HR – employment agreements, HR policies, termination letters, NDAs, resignation or separation terms.\n",
    "8. Finance and Banking – loan terms, guarantee clauses, investment contracts, collateral agreements, promissory notes.\n",
    "9. Government and Public Laws – public notices, licenses, Right to Information (RTI) references, certificates issued by authorities.\n",
    "10. Personal and Civil Legal Documents – ID proofs, marriage/divorce certificates, affidavits, inheritance documents, family law terms.\n",
    "11. Others – anything that doesn’t fit above but still contains legal relevance.\n",
    "\n",
    "Return the most relevant parts verbatim that clearly show which category the document may belong to.\n",
    "\"\"\"\n",
    "\n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Thanks for using the classifier!\")\n",
    "            break\n",
    "        similar_chunks = db.similarity_search(query, k=5)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in similar_chunks])\n",
    "        try:\n",
    "            response = model1(context=context, query=query, chat=chat, model=model, tokenizer=tokenizer,maxlen=2048)\n",
    "            # print(\"\\n[Model Output]:\\n\", response.strip(), \"\\n\")\n",
    "            chat = response\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error during inference]: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108b449-8bb9-45bc-a821-ca70087beadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Contractual  like B2B or B2C etc\n",
    "# 2. Regulatory and Compliance  like Internal compliance and External regulatory submission etc\n",
    "# 3. Intellectual Property Rights (IPR) like patent, copyright, trademarks , trade secrets, design etc\n",
    "# 4. Litigation and Dispute  like pleadings and petitions, court orders and judegements , arbitration etc\n",
    "# 5. Property and Real Estate  like ownership transfer,lease/rental,land records etc\n",
    "# 6. Corporate and Governance  like Foundational document,corporate actions, annual repors and filings etc\n",
    "# 7. Employment and Human Resources (HR)  like employee contracts, HR policy, seperation Docs(resignation) etc\n",
    "# 8. Finance and Banking  loan documents, gurantees and collaterals, investment agreements etc\n",
    "# 9. Government and Public Laws  licences, public notices, rti, certificates etc\n",
    "# 10. Personal and Civil Legal Documents  Identiy, affidavites, family laws etc\n",
    "# 11. Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22914336-2ca3-4c13-baf8-d32c79024c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f\"\"\"You are a legal assistant that classifies legal documents based **strictly** on the provided context.\n",
    "\n",
    "\n",
    "# Please follow this format exactly:\n",
    "\n",
    "\n",
    "# <think>\n",
    "\n",
    "# Step-by-step legal reasoning based **only** on the context.\n",
    "\n",
    "#     1.Identify the **document type** (e.g., act, contract, judgment, petition) using only terms directly visible in the context.\n",
    "\n",
    "#     2.List exact **legal terms, sections, or phrases** (e.g., \"petition\", \"statute\", \"employment\", \"IPR\", \"compliance\", \"court\", etc.) found in the text. Do not interpret — quote them exactly.\n",
    "\n",
    "#     3.Check for **structural indicators**:\n",
    "\n",
    "#        - Are there section numbers? → Could indicate a statute.\n",
    "\n",
    "#        - Are there parties, rulings, judgments, or citations? → Could indicate litigation.\n",
    "\n",
    "#        - Are there terms like \"agreement\", \"obligations\", \"consideration\"? → Could indicate contracts.\n",
    "\n",
    "#     4.Eliminate each incorrect category **one by one**, using direct contradictions or lack of evidence.\n",
    "\n",
    "#     5.Final Decision: Choose only the category that is **explicitly and unambiguously supported** by the language or structure in the context.\n",
    "\n",
    "#     6.If you have to guess or cannot find conclusive evidence for any listed category, select **\"11. Others\"**.\n",
    "\n",
    "\n",
    "# Remember:\n",
    "\n",
    "# - You must behave like a legal auditor under oath.\n",
    "\n",
    "# - Do not infer meaning, do not rely on general knowledge, and do not use legal intuition — only analyze what is present in the context.\n",
    "\n",
    "# - Your reasoning must be slow, careful, and legally justifiable at every step.\n",
    "\n",
    "# </think>\n",
    "\n",
    "# <answer>\n",
    "\n",
    "# Respond with only one category from this exact list — nothing else:\n",
    "\n",
    "\n",
    "# 1. Contractual  \n",
    "\n",
    "# 2. Regulatory and Compliance  \n",
    "\n",
    "# 3. Intellectual Property Rights (IPR)  \n",
    "\n",
    "# 4. Litigation and Dispute  \n",
    "\n",
    "# 5. Property and Real Estate  \n",
    "\n",
    "# 6. Corporate and Governance  \n",
    "\n",
    "# 7. Employment and Human Resources (HR)  \n",
    "\n",
    "# 8. Finance and Banking  \n",
    "\n",
    "# 9. Government and Public Laws  \n",
    "\n",
    "# 10. Personal and Civil Legal Documents\n",
    "\n",
    "# 11. Others\n",
    "\n",
    "# Your response must **exactly match one of these options** (e.g., `4. Litigation and Dispute`). Do **not** generate any answer outside this list.\n",
    "\n",
    "# </answer>\n",
    "\n",
    "\n",
    "# <context>\n",
    "\n",
    "# {context}\n",
    "\n",
    "# </context>\n",
    "\n",
    "\n",
    "# Question: What is the correct legal category for this document?\n",
    "\n",
    "# \"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63177c6-4356-4fe2-a9ee-a0a08a6b85fc",
   "metadata": {},
   "source": [
    "# LLama 3.2 1B (Good working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9d1b4-845d-4e16-8646-2b3b9bb3e58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc488bd8-d381-4ff8-a87c-151297d08ddb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a06e0ea-5652-4b82-96c1-9b8ade0f4084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFacePipeline\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM,BitsAndBytesConfig,StoppingCriteria, StoppingCriteriaList\n",
    "import torch\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736d37f8-fd14-49ec-9cf1-82b676599139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Stream(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, stop_token_id=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stop_token_id = stop_token_id\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        new_token_id = input_ids[0, -1].item()\n",
    "        if self.stop_token_id is not None and new_token_id == self.stop_token_id:\n",
    "            return True\n",
    "        token_text = self.tokenizer.decode([new_token_id], skip_special_tokens=False)\n",
    "        print(token_text, end=\"\", flush=True)\n",
    "        return False\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def loading_pdf(path=\"/home/pa2/ml/Document-Classification/files/1_D:\\BPL\\BLS\\Document\\Arbitration Award of Zostel Hospitality relied upon by the Claimant.txt\"):\n",
    "    \"\"\"Loads a text file and splits it into chunks.\"\"\"\n",
    "    loader = TextLoader(path, encoding=\"utf-8\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    \n",
    "    return docs\n",
    "    \n",
    "def faiss1(docs):\n",
    "    model=HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "    )\n",
    "    db=FAISS.from_documents(docs,model)\n",
    "    return db\n",
    "def model1(context,query,chat,model,tokenizer,maxlen=3000):\n",
    "    \n",
    "    message = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"You are a legal assistant trained to classify legal documents with zero tolerance for guessing. You must follow the rules below strictly:\n",
    "\n",
    "RULES:\n",
    "1. Do NOT make assumptions or use external knowledge.\n",
    "2. ONLY use exact words, legal terms, and structures from the given context.\n",
    "3. You MUST explain your classification using legal terminology from the context.\n",
    "4. You MUST follow the exact output format below.\n",
    "5. Return one and only one category from the list below.\n",
    "\n",
    "LEGAL CATEGORIES with EXAMPLES:\n",
    "\n",
    "1. Contractual – (e.g., B2B agreements, purchase orders, NDAs, service contracts)  \n",
    "2. Regulatory and Compliance – (e.g., compliance reports, internal audits, regulatory filings)  \n",
    "3. Intellectual Property Rights (IPR) – (e.g., patents, trademarks, copyrights, design rights, trade secrets)  \n",
    "4. Litigation and Dispute – (e.g., court filings, legal notices, arbitration claims, judgments)  \n",
    "5. Property and Real Estate – (e.g., lease agreements, sale deeds, land registration, rent contracts)  \n",
    "6. Corporate and Governance – (e.g., company formation docs, resolutions, board meeting records, annual filings)  \n",
    "7. Employment and Human Resources (HR) – (e.g., employee contracts, HR policies, separation letters)  \n",
    "8. Finance and Banking – (e.g., loan agreements, collateral deeds, investment deals, bank guarantees)  \n",
    "9. Government and Public Laws – (e.g., RTI responses, government licenses, public notices, certificates)  \n",
    "10. Personal and Civil Legal Documents – (e.g., ID proofs, affidavits, marriage/divorce documents, family law papers)  \n",
    "11. Others – (Only if no other category fits)\n",
    "\n",
    "---\n",
    "MANDATORY RULE MUST FOLLOW :-\n",
    "-> **PROPERLY SHOW ALL THE STEPS IN <think> SECTION** (MANDATORY)\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "---\n",
    "\n",
    "<think>Steps\n",
    "\n",
    "Step 1: Extracted Legal Keywords →  \n",
    "[List all legal terms, phrases, and document structures found directly in the context.]\n",
    "\n",
    "Step 2: Short Legal Summary →  \n",
    "[Summarize the context in 2–3 lines using legal wording, sticking strictly to the content.]\n",
    "\n",
    "Step 3: Multi-Angle Rethinking →  \n",
    "[Restate the summary from multiple angles: formal, casual, detailed, abstract, technical.]\n",
    "\n",
    "Step 4: Category Matching →  \n",
    "[Compare summary + keywords against each category. Write your thought process for every match or mismatch.]\n",
    "\n",
    "Step 5: Eliminate Unrelated Categories →  \n",
    "[List all categories that clearly do NOT apply and briefly explain why.]\n",
    "\n",
    "Step 6: Deep Legal Reasoning →  \n",
    "[Based on the remaining options, explain in detail why one specific category is the strongest fit using legal logic.]\n",
    "\n",
    "Step 7: Final Justification →  \n",
    "[Final 1-2 lines defending your classification using exact phrases or structure from the context.]\n",
    "\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "Choose ONLY ONE from this list (copy-paste one line only):\n",
    "\n",
    "1. Contractual  \n",
    "2. Regulatory and Compliance  \n",
    "3. Intellectual Property Rights (IPR)  \n",
    "4. Litigation and Dispute  \n",
    "5. Property and Real Estate  \n",
    "6. Corporate and Governance  \n",
    "7. Employment and Human Resources (HR)  \n",
    "8. Finance and Banking  \n",
    "9. Government and Public Laws  \n",
    "10. Personal and Civil Legal Documents  \n",
    "11. Others\n",
    "</answer>\n",
    "\n",
    "\n",
    "Question: What is the correct legal category for this document?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    }]\n",
    "\n",
    "    prompt=tokenizer.apply_chat_template(message,tokenize=False)\n",
    "    input_ids=tokenizer(prompt,return_tensors='pt').to(\"cuda\")\n",
    "    stopping_criteria = StoppingCriteriaList([Stream(tokenizer)])\n",
    "    with torch.no_grad():\n",
    "        response=model.generate(input_ids=input_ids['input_ids'],\n",
    "                                attention_mask=input_ids['attention_mask'],\n",
    "                                stopping_criteria=stopping_criteria,\n",
    "                                max_new_tokens=maxlen,\n",
    "                                use_cache=True,\n",
    "                               temperature=0.1,)\n",
    "    answer=tokenizer.decode(response[0])\n",
    "    print()\n",
    "    return answer\n",
    "def loading_pdf1(path):\n",
    "    \"\"\"Loads a PDF or text file and splits it into chunks.\"\"\"\n",
    "    if path.endswith(\".txt\"):\n",
    "        loader = TextLoader(path, encoding=\"utf-8\")\n",
    "    elif path.lower().endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Only .txt and .pdf are supported.\")\n",
    "\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    return docs\n",
    "# docs=loading_pdf()\n",
    "docs=loading_pdf1(\"/home/pa2/ml/Document-Classification/files/AL6988A-BPL-20240601-001.pdf\")\n",
    "db=faiss1(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be14de3e-d3cb-4820-bb5d-7c564c372268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df349f9cd0f0487881a65eeac6507b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.1-8B-Instruct')\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4'\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'meta-llama/Llama-3.1-8B-Instruct',\n",
    "    device_map='cuda',\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f148eecc-2be0-4813-871f-a4a1260ca1c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<think>\n",
      "\n",
      "Step 1: Extracted Legal Keywords  \n",
      "[List all legal terms, phrases, and document structures found directly in the context.]\n",
      "\n",
      "- Invoice\n",
      "- Letter of Credit (LC)\n",
      "- Authorized Dealer (AD)\n",
      "- High Sea Sale (HSS)\n",
      "- Commission & Brokerage\n",
      "- Cost of Container (CoC)\n",
      "- Cost of Packing (CoP)\n",
      "- Handling Charges (HND CHG)\n",
      "- Goods and Service input cost (G&S)\n",
      "- Document Charges (DOC CH)\n",
      "- Country of Origin Certificate (CoO)\n",
      "- Royalty and Licence Fees (R&LF)\n",
      "- Loading Unloading Charges (LD/ULD)\n",
      "- Warranty Services (WS)\n",
      "- Other Costs (OTC)\n",
      "- Customs Tariff Head (CTH)\n",
      "- Unit Quantity Code (UQC)\n",
      "\n",
      "Step 2: Short Legal Summary  \n",
      "[Summarize the context in 2–3 lines using legal wording, sticking strictly to the content.]\n",
      "\n",
      "This document appears to be a commercial invoice detailing goods and services provided, including charges and fees associated with their transportation and documentation.\n",
      "\n",
      "Step 3: Multi-Angle Rethinking  \n",
      "[Restate the summary from multiple angles: formal, casual, detailed, abstract, technical.]\n",
      "\n",
      "- Formal: The document is a commercial invoice outlining goods and services provided.\n",
      "- Casual: It's a bill for goods and services with various charges.\n",
      "- Detailed: The invoice includes specific charges for transportation, documentation, and other services.\n",
      "- Abstract: A commercial transaction document detailing goods and services.\n",
      "- Technical: The document utilizes standardized codes for customs and trade purposes.\n",
      "\n",
      "Step 4: Category Matching  \n",
      "[Compare summary + keywords against each category. Write your thought process for every match or mismatch.]\n",
      "\n",
      "- Contractual: The document appears to be related to a commercial transaction, which could be contractual in nature.\n",
      "- Regulatory and Compliance: There are references to customs and trade regulations, but it's not primarily a compliance document.\n",
      "- Intellectual Property Rights (IPR): No IPR-related terms are mentioned.\n",
      "- Litigation and Dispute: No dispute or litigation-related terms are present.\n",
      "- Property and Real Estate: No property or real estate-related terms are mentioned.\n",
      "- Corporate and Governance: No corporate governance or company formation terms are present.\n",
      "- Employment and Human Resources (HR): No employment or HR-related terms are mentioned.\n",
      "- Finance and Banking: The document involves financial transactions, but it's not primarily a banking or financial agreement.\n",
      "- Government and Public Laws: The document involves customs and trade regulations, but it's not a government or public law document.\n",
      "- Personal and Civil Legal Documents: No personal or civil law-related terms are mentioned.\n",
      "- Others: This category could potentially apply if none of the other categories fit.\n",
      "\n",
      "Step 5: Eliminate Unrelated Categories  \n",
      "[List all categories that clearly do NOT apply and briefly explain why.]\n",
      "\n",
      "- Intellectual Property Rights (IPR): No IPR-related terms are mentioned.\n",
      "- Litigation and Dispute: No dispute or litigation-related terms are present.\n",
      "- Property and Real Estate: No property or real estate-related terms are mentioned.\n",
      "- Corporate and Governance: No corporate governance or company formation terms are present.\n",
      "- Employment and Human Resources (HR): No employment or HR-related terms are mentioned.\n",
      "- Personal and Civil Legal Documents: No personal or civil law-related terms are mentioned.\n",
      "\n",
      "Step 6: Deep Legal Reasoning  \n",
      "[Based on the remaining options, explain in detail why one specific category is the strongest fit using legal logic.]\n",
      "\n",
      "Considering the commercial nature of the document, the presence of standardized codes for customs and trade purposes, and the detailed listing of goods and services provided, the strongest fit appears to be the Contractual category. This is because the document outlines a commercial transaction, which is a fundamental aspect of contractual law.\n",
      "\n",
      "Step 7: Final Justification  \n",
      "[Final 1-2 lines defending your classification using exact phrases or structure from the context.]\n",
      "\n",
      "The document is a commercial invoice, which is a contractual agreement between the seller and buyer, as evident from the detailed listing of goods and services provided (e.g., \"A : LC - Letter of Credit; B : AD - Authorized Dealer; C : HSS - High Sea Sale;...\").\n",
      "\n",
      "<answer>\n",
      "1. Contractual<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    chat = \"\"\n",
    "    \n",
    "    while True:\n",
    "        query = \"\"\"Retrieve the most informative sections of this legal document that can help determine its legal classification. Prioritize segments containing legal terms, section headings, clauses, named parties, obligations, dates, and governing laws. Specifically look for any signs related to:\n",
    "\n",
    "1. Contractual – references to B2B or B2C agreements, terms and conditions, service-level agreements, non-disclosure agreements, etc.\n",
    "2. Regulatory and Compliance – internal audit language, compliance obligations, policy enforcement, external submissions to government bodies.\n",
    "3. Intellectual Property Rights (IPR) – mentions of patents, copyrights, trademarks, trade secrets, licenses, or intellectual asset ownership.\n",
    "4. Litigation and Dispute – phrases like \"court order\", \"petition\", \"judgment\", \"arbitration\", \"claim\", or \"legal dispute\".\n",
    "5. Property and Real Estate – lease terms, ownership transfers, land records, mortgage agreements, property deeds.\n",
    "6. Corporate and Governance – company founding documents, board resolutions, shareholder agreements, filings, annual reports.\n",
    "7. Employment and HR – employment agreements, HR policies, termination letters, NDAs, resignation or separation terms.\n",
    "8. Finance and Banking – loan terms, guarantee clauses, investment contracts, collateral agreements, promissory notes.\n",
    "9. Government and Public Laws – public notices, licenses, Right to Information (RTI) references, certificates issued by authorities.\n",
    "10. Personal and Civil Legal Documents – ID proofs, marriage/divorce certificates, affidavits, inheritance documents, family law terms.\n",
    "11. Others – anything that doesn’t fit above but still contains legal relevance.\n",
    "\n",
    "\n",
    "Return the most relevant parts verbatim that clearly show which category the document may belong to.\n",
    "\"\"\"\n",
    "\n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Thanks for using the classifier!\")\n",
    "            break\n",
    "        similar_chunks = db.similarity_search(query, k=5)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in similar_chunks])\n",
    "        try:\n",
    "            response = model1(context=context, query=query, chat=chat, model=model, tokenizer=tokenizer,maxlen=2048)\n",
    "            # print(\"\\n[Model Output]:\\n\", response.strip(), \"\\n\")\n",
    "            chat = response\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error during inference]: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c81ff9-9305-4ef0-b4b7-fe9d00ce097f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "You are a legal assistant trained to classify legal documents with zero tolerance for guessing. You must follow the rules below strictly:\n",
      "\n",
      "RULES:\n",
      "1. Do NOT make assumptions or use external knowledge.\n",
      "2. ONLY use exact words, legal terms, and structures from the given context.\n",
      "3. You MUST explain your classification using legal terminology from the context.\n",
      "4. You MUST follow the exact output format below.\n",
      "5. Return one and only one category from the list below.\n",
      "\n",
      "LEGAL CATEGORIES with EXAMPLES:\n",
      "\n",
      "1. Contractual – (e.g., B2B agreements, purchase orders, NDAs, service contracts)  \n",
      "2. Regulatory and Compliance – (e.g., compliance reports, internal audits, regulatory filings)  \n",
      "3. Intellectual Property Rights (IPR) – (e.g., patents, trademarks, copyrights, design rights, trade secrets)  \n",
      "4. Litigation and Dispute – (e.g., court filings, legal notices, arbitration claims, judgments)  \n",
      "5. Property and Real Estate – (e.g., lease agreements, sale deeds, land registration, rent contracts)  \n",
      "6. Corporate and Governance – (e.g., company formation docs, resolutions, board meeting records, annual filings)  \n",
      "7. Employment and Human Resources (HR) – (e.g., employee contracts, HR policies, separation letters)  \n",
      "8. Finance and Banking – (e.g., loan agreements, collateral deeds, investment deals, bank guarantees)  \n",
      "9. Government and Public Laws – (e.g., RTI responses, government licenses, public notices, certificates)  \n",
      "10. Personal and Civil Legal Documents – (e.g., ID proofs, affidavits, marriage/divorce documents, family law papers)  \n",
      "11. Others – (Only if no other category fits)\n",
      "\n",
      "---\n",
      "MANDATORY RULE MUST FOLLOW :-\n",
      "-> **PROPERLY SHOW ALL THE STEPS IN <think> SECTION** (MANDATORY)\n",
      "<context>\n",
      "INVOICE\n",
      "A.\n",
      "ITEM DETAILS\n",
      "E.\n",
      " A : LC - Letter of Credit; B : AD - Authorized Dealer; C : HSS - High Sea Sale;  D : C&B Commission & Brokerage, CoC - Cost of Container,CoP - Co\n",
      " of  Packing, HND CHG - Handling Charges, G&S - Goods and Service input cost, DOC CH - Document Charges, CoO - Country of Origin Certificate,\n",
      "GLOSSARY\n",
      " R&LF - Royalty and Licence Fees, LD/ULD - Loading Unloading Charges, WS - Warranty Services, OTC - Other Costs, CTH - Customs Tariff Head,  \n",
      " UQC - Unit Quantity Code\n",
      "\n",
      "of  Packing, HND CHG - Handling Charges, G&S - Goods and Service input cost, DOC CH - Document Charges, CoO - Country of Origin Certificate,\n",
      "GLOSSARY\n",
      "VALUATION\n",
      "6. AD CODE 0510005\n",
      " R&LF - Royalty and Licence Fees, LD/ULD - Loading Unloading Charges, WS - Warranty Services, OTC - Other Costs, CTH - Customs Tariff Head,  \n",
      " UQC - Unit Quantity Code\n",
      "\n",
      "85340000\n",
      "85340000\n",
      ")\n",
      "1.S.NO 2.INVOICE NO. & DT. 3.PURCHASE ORDER NO & DT 4.LC NO & DATE 5.CONTRACT NO & DATE\n",
      "1.S NO. 2.CTH 3.DESCRIPTION 4.UNIT PRICE 5.QUANTITY 6.UQC 7.AMOUNT\n",
      "INVOICE\n",
      "A.\n",
      "ITEM DETAILS\n",
      "E.\n",
      " A : LC - Letter of Credit; B : AD - Authorized Dealer; C : HSS - High Sea Sale;  D : C&B Commission & Brokerage, CoC - Cost of Container,CoP - Co\n",
      " of  Packing, HND CHG - Handling Charges, G&S - Goods and Service input cost, DOC CH - Document Charges, CoO - Country of Origin Certificate,\n",
      "GLOSSARY\n",
      " R&LF - Royalty and Licence Fees, LD/ULD - Loading Unloading Charges, WS - Warranty Services, OTC - Other Costs, CTH - Customs Tariff Head,  \n",
      " UQC - Unit Quantity Code\n",
      "\n",
      "A.\n",
      "ITEM DETAILS\n",
      "E.\n",
      " A : LC - Letter of Credit; B : AD - Authorized Dealer; C : HSS - High Sea Sale;  D : C&B Commission & Brokerage, CoC - Cost of Container,CoP - Co\n",
      " of  Packing, HND CHG - Handling Charges, G&S - Goods and Service input cost, DOC CH - Document Charges, CoO - Country of Origin Certificate,\n",
      "GLOSSARY\n",
      " R&LF - Royalty and Licence Fees, LD/ULD - Loading Unloading Charges, WS - Warranty Services, OTC - Other Costs, CTH - Customs Tariff Head,  \n",
      " UQC - Unit Quantity Code\n",
      "\n",
      "A.\n",
      "ITEM DETAILS\n",
      "E.\n",
      " A : LC - Letter of Credit; B : AD - Authorized Dealer; C : HSS - High Sea Sale;  D : C&B Commission & Brokerage, CoC - Cost of Container,CoP - Co\n",
      " of  Packing, HND CHG - Handling Charges, G&S - Goods and Service input cost, DOC CH - Document Charges, CoO - Country of Origin Certificate,\n",
      "GLOSSARY\n",
      " R&LF - Royalty and Licence Fees, LD/ULD - Loading Unloading Charges, WS - Warranty Services, OTC - Other Costs, CTH - Customs Tariff Head,  \n",
      " UQC - Unit Quantity Code\n",
      "</context>\n",
      "\n",
      "---\n",
      "\n",
      "<think>Steps\n",
      "\n",
      "Step 1: Extracted Legal Keywords →  \n",
      "[List all legal terms, phrases, and document structures found directly in the context.]\n",
      "\n",
      "Step 2: Short Legal Summary →  \n",
      "[Summarize the context in 2–3 lines using legal wording, sticking strictly to the content.]\n",
      "\n",
      "Step 3: Multi-Angle Rethinking →  \n",
      "[Restate the summary from multiple angles: formal, casual, detailed, abstract, technical.]\n",
      "\n",
      "Step 4: Category Matching →  \n",
      "[Compare summary + keywords against each category. Write your thought process for every match or mismatch.]\n",
      "\n",
      "Step 5: Eliminate Unrelated Categories →  \n",
      "[List all categories that clearly do NOT apply and briefly explain why.]\n",
      "\n",
      "Step 6: Deep Legal Reasoning →  \n",
      "[Based on the remaining options, explain in detail why one specific category is the strongest fit using legal logic.]\n",
      "\n",
      "Step 7: Final Justification →  \n",
      "[Final 1-2 lines defending your classification using exact phrases or structure from the context.]\n",
      "\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "Choose ONLY ONE from this list (copy-paste one line only):\n",
      "\n",
      "1. Contractual  \n",
      "2. Regulatory and Compliance  \n",
      "3. Intellectual Property Rights (IPR)  \n",
      "4. Litigation and Dispute  \n",
      "5. Property and Real Estate  \n",
      "6. Corporate and Governance  \n",
      "7. Employment and Human Resources (HR)  \n",
      "8. Finance and Banking  \n",
      "9. Government and Public Laws  \n",
      "10. Personal and Civil Legal Documents  \n",
      "11. Others\n",
      "</answer>\n",
      "\n",
      "\n",
      "Question: What is the correct legal category for this document?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<think>\n",
      "\n",
      "Step 1: Extracted Legal Keywords  \n",
      "[List all legal terms, phrases, and document structures found directly in the context.]\n",
      "\n",
      "- Invoice\n",
      "- Letter of Credit (LC)\n",
      "- Authorized Dealer (AD)\n",
      "- High Sea Sale (HSS)\n",
      "- Commission & Brokerage\n",
      "- Cost of Container (CoC)\n",
      "- Cost of Packing (CoP)\n",
      "- Handling Charges (HND CHG)\n",
      "- Goods and Service input cost (G&S)\n",
      "- Document Charges (DOC CH)\n",
      "- Country of Origin Certificate (CoO)\n",
      "- Royalty and Licence Fees (R&LF)\n",
      "- Loading Unloading Charges (LD/ULD)\n",
      "- Warranty Services (WS)\n",
      "- Other Costs (OTC)\n",
      "- Customs Tariff Head (CTH)\n",
      "- Unit Quantity Code (UQC)\n",
      "\n",
      "Step 2: Short Legal Summary  \n",
      "[Summarize the context in 2–3 lines using legal wording, sticking strictly to the content.]\n",
      "\n",
      "This document appears to be a commercial invoice detailing goods and services provided, including charges and fees associated with their transportation and documentation.\n",
      "\n",
      "Step 3: Multi-Angle Rethinking  \n",
      "[Restate the summary from multiple angles: formal, casual, detailed, abstract, technical.]\n",
      "\n",
      "- Formal: The document is a commercial invoice outlining goods and services provided.\n",
      "- Casual: It's a bill for goods and services with various charges.\n",
      "- Detailed: The invoice includes specific charges for transportation, documentation, and other services.\n",
      "- Abstract: A commercial transaction document detailing goods and services.\n",
      "- Technical: The document utilizes standardized codes for customs and trade purposes.\n",
      "\n",
      "Step 4: Category Matching  \n",
      "[Compare summary + keywords against each category. Write your thought process for every match or mismatch.]\n",
      "\n",
      "- Contractual: The document appears to be related to a commercial transaction, which could be contractual in nature.\n",
      "- Regulatory and Compliance: There are references to customs and trade regulations, but it's not primarily a compliance document.\n",
      "- Intellectual Property Rights (IPR): No IPR-related terms are mentioned.\n",
      "- Litigation and Dispute: No dispute or litigation-related terms are present.\n",
      "- Property and Real Estate: No property or real estate-related terms are mentioned.\n",
      "- Corporate and Governance: No corporate governance or company formation terms are present.\n",
      "- Employment and Human Resources (HR): No employment or HR-related terms are mentioned.\n",
      "- Finance and Banking: The document involves financial transactions, but it's not primarily a banking or financial agreement.\n",
      "- Government and Public Laws: The document involves customs and trade regulations, but it's not a government or public law document.\n",
      "- Personal and Civil Legal Documents: No personal or civil law-related terms are mentioned.\n",
      "- Others: This category could potentially apply if none of the other categories fit.\n",
      "\n",
      "Step 5: Eliminate Unrelated Categories  \n",
      "[List all categories that clearly do NOT apply and briefly explain why.]\n",
      "\n",
      "- Intellectual Property Rights (IPR): No IPR-related terms are mentioned.\n",
      "- Litigation and Dispute: No dispute or litigation-related terms are present.\n",
      "- Property and Real Estate: No property or real estate-related terms are mentioned.\n",
      "- Corporate and Governance: No corporate governance or company formation terms are present.\n",
      "- Employment and Human Resources (HR): No employment or HR-related terms are mentioned.\n",
      "- Personal and Civil Legal Documents: No personal or civil law-related terms are mentioned.\n",
      "\n",
      "Step 6: Deep Legal Reasoning  \n",
      "[Based on the remaining options, explain in detail why one specific category is the strongest fit using legal logic.]\n",
      "\n",
      "Considering the commercial nature of the document, the presence of standardized codes for customs and trade purposes, and the detailed listing of goods and services provided, the strongest fit appears to be the Contractual category. This is because the document outlines a commercial transaction, which is a fundamental aspect of contractual law.\n",
      "\n",
      "Step 7: Final Justification  \n",
      "[Final 1-2 lines defending your classification using exact phrases or structure from the context.]\n",
      "\n",
      "The document is a commercial invoice, which is a contractual agreement between the seller and buyer, as evident from the detailed listing of goods and services provided (e.g., \"A : LC - Letter of Credit; B : AD - Authorized Dealer; C : HSS - High Sea Sale;...\").\n",
      "\n",
      "<answer>\n",
      "1. Contractual<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b601251-a572-4843-a365-a1ad869f31e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<think>\n",
      "\n",
      "Step 1: Extracted Legal Keywords  \n",
      "[Patent, U.S. Patent, U.S. Patent application, invention, embodiment, clamping circuit, components, flow chart, fabricating, internal conductors, wires, conductors, node, ground path, transient voltages, clamping circuit, components, transZorbs, fast-acting diodes, TVS Zener diodes, arrestor devices, metal oxide varistors, carbon blocks, thyristors, gas discharge tubes, cable, internal conductors, wires, conductors, node, ground path, transient voltages, clamping circuit, components, transZorbs, fast-acting diodes, TVS Zener diodes, arrestor devices, metal oxide varistors, carbon blocks, thyristors, gas discharge tubes]\n",
      "\n",
      "Step 2: Short Legal Summary  \n",
      "This document pertains to a U.S. Patent application describing an invention involving a clamping circuit and components for protecting against transient voltages.\n",
      "\n",
      "Step 3: Multi-Angle Rethinking  \n",
      "Formally, this document is a patent application. Casually, it's a description of a circuit design. In detail, it outlines a specific invention involving a clamping circuit. Abstractly, it's a technical description of a device. Technically, it's a patent application detailing a circuit design.\n",
      "\n",
      "Step 4: Category Matching  \n",
      "- Category 1: Contractual - No match, as it's not a contract.\n",
      "- Category 2: Regulatory and Compliance - No match, as it's not a regulatory or compliance document.\n",
      "- Category 3: Intellectual Property Rights (IPR) - Potential match, as it's a patent application.\n",
      "- Category 4: Litigation and Dispute - No match, as it's not a dispute or litigation document.\n",
      "- Category 5: Property and Real Estate - No match, as it's not related to property or real estate.\n",
      "- Category 6: Corporate and Governance - No match, as it's not a corporate or governance document.\n",
      "- Category 7: Employment and Human Resources (HR) - No match, as it's not an employment or HR document.\n",
      "- Category 8: Finance and Banking - No match, as it's not a financial or banking document.\n",
      "- Category 9: Government and Public Laws - No match, as it's not a government or public law document.\n",
      "- Category 10: Personal and Civil Legal Documents - No match, as it's not a personal or civil legal document.\n",
      "- Category 11: Others - Potential match, as it doesn't fit into any other category.\n",
      "\n",
      "Step 5: Eliminate Unrelated Categories  \n",
      "Categories 1, 2, 4, 5, 6, 7, 8, 9, 10 are eliminated as they do not match the content.\n",
      "\n",
      "Step 6: Deep Legal Reasoning  \n",
      "The document is a patent application, which is a type of intellectual property right. It describes an invention and its components, which is a key aspect of intellectual property law. The use of technical terms such as \"clamping circuit,\" \"transZorbs,\" and \"TVS Zener diodes\" further supports this classification.\n",
      "\n",
      "Step 7: Final Justification  \n",
      "Based on the presence of a patent application and technical descriptions of an invention, the strongest fit is Category 3: Intellectual Property Rights (IPR).\n",
      "\n",
      "<answer>\n",
      "3. Intellectual Property Rights (IPR)<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    chat = \"\"\n",
    "    \n",
    "    while True:\n",
    "        query = \"\"\"Retrieve the most informative sections of this legal document that can help determine its legal classification. Prioritize segments containing legal terms, section headings, clauses, named parties, obligations, dates, and governing laws. Specifically look for any signs related to:\n",
    "\n",
    "1. Contractual – references to B2B or B2C agreements, terms and conditions, service-level agreements, non-disclosure agreements, etc.\n",
    "2. Regulatory and Compliance – internal audit language, compliance obligations, policy enforcement, external submissions to government bodies.\n",
    "3. Intellectual Property Rights (IPR) – mentions of patents, copyrights, trademarks, trade secrets, licenses, or intellectual asset ownership.\n",
    "4. Litigation and Dispute – phrases like \"court order\", \"petition\", \"judgment\", \"arbitration\", \"claim\", or \"legal dispute\".\n",
    "5. Property and Real Estate – lease terms, ownership transfers, land records, mortgage agreements, property deeds.\n",
    "6. Corporate and Governance – company founding documents, board resolutions, shareholder agreements, filings, annual reports.\n",
    "7. Employment and HR – employment agreements, HR policies, termination letters, NDAs, resignation or separation terms.\n",
    "8. Finance and Banking – loan terms, guarantee clauses, investment contracts, collateral agreements, promissory notes.\n",
    "9. Government and Public Laws – public notices, licenses, Right to Information (RTI) references, certificates issued by authorities.\n",
    "10. Personal and Civil Legal Documents – ID proofs, marriage/divorce certificates, affidavits, inheritance documents, family law terms.\n",
    "11. Others – anything that doesn’t fit above but still contains legal relevance.\n",
    "\n",
    "Return the most relevant parts verbatim that clearly show which category the document may belong to.\n",
    "\"\"\"\n",
    "\n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Thanks for using the classifier!\")\n",
    "            break\n",
    "        similar_chunks = db.similarity_search(query, k=5)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in similar_chunks])\n",
    "        try:\n",
    "            response = model1(context=context, query=query, chat=chat, model=model, tokenizer=tokenizer,maxlen=2048)\n",
    "            # print(\"\\n[Model Output]:\\n\", response.strip(), \"\\n\")\n",
    "            chat = response\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error during inference]: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43d1dc51-f123-4d0d-971d-3c4753e147ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<think>\n",
      "\n",
      "Step 1: Extracted Legal Keywords  \n",
      "[List all legal terms, phrases, and document structures found directly in the context.]\n",
      "\n",
      "- W.P.(C) No. (Court Case Number)\n",
      "- IA No. (Intervention Application Number)\n",
      "- Intervention/Application\n",
      "- Ex-Parte Stay\n",
      "- Permission to File\n",
      "- Lengthy List of Dates\n",
      "- Grant of Interim Relief\n",
      "- Clarification/Direction\n",
      "- Early Hearing Application\n",
      "- Intervention/Impleadment\n",
      "- Criminal law\n",
      "- Trade and commerce\n",
      "- Price control\n",
      "- Union List\n",
      "- Concurrent List\n",
      "- State List\n",
      "- Article 19\n",
      "- Article 35(C)\n",
      "- CO (Circular Order)\n",
      "- Marginal note\n",
      "- Section\n",
      "- Interpretation\n",
      "- Constitution\n",
      "- Finance\n",
      "- Property\n",
      "- Contracts\n",
      "- Suits\n",
      "\n",
      "Step 2: Short Legal Summary  \n",
      "[Summarize the context in 2–3 lines using legal wording, sticking strictly to the content.]\n",
      "\n",
      "The document appears to be a collection of court case numbers and intervention applications related to various legal matters, including constitutional interpretation, criminal law, and trade regulations.\n",
      "\n",
      "Step 3: Multi-Angle Rethinking  \n",
      "[Restate the summary from multiple angles: formal, casual, detailed, abstract, technical.]\n",
      "\n",
      "Formal: The document contains a list of court case numbers and intervention applications related to constitutional interpretation and legal matters.\n",
      "Casual: It's a bunch of court case numbers and intervention applications about various legal stuff.\n",
      "Detailed: The document comprises a collection of court case numbers and intervention applications related to constitutional interpretation, criminal law, and trade regulations, including specific references to the Constitution and various laws.\n",
      "Abstract: The document is a compilation of legal case numbers and intervention applications.\n",
      "Technical: The document contains a list of court case numbers and intervention applications related to constitutional interpretation, including references to specific sections and articles of the Constitution.\n",
      "\n",
      "Step 4: Eliminate Unrelated Categories  \n",
      "[List all categories that clearly do NOT apply and briefly explain why.]\n",
      "\n",
      "- Contractual: The document does not mention any contractual agreements or terms.\n",
      "- Intellectual Property Rights (IPR): There is no mention of patents, trademarks, copyrights, or other intellectual property rights.\n",
      "- Property and Real Estate: The document does not discuss property or real estate matters.\n",
      "- Employment and Human Resources (HR): There is no mention of employment or HR-related issues.\n",
      "- Finance and Banking: The document does not discuss financial or banking matters.\n",
      "- Personal and Civil Legal Documents: The document does not appear to be a personal or civil legal document.\n",
      "\n",
      "Step 5: Deep Legal Reasoning  \n",
      "[Based on the remaining options, explain in detail why one specific category is the strongest fit using legal logic.]\n",
      "\n",
      "The document appears to be related to legal matters, specifically constitutional interpretation, criminal law, and trade regulations. The mention of court case numbers, intervention applications, and references to specific sections and articles of the Constitution suggest that the document is related to legal proceedings and the application of laws. The strongest fit for this document is the Government and Public Laws category, as it deals with the interpretation and application of laws, including constitutional laws.\n",
      "\n",
      "Step 6: Final Justification  \n",
      "[Final 1-2 lines defending your classification using exact phrases or structure from the context.]\n",
      "\n",
      "The document is a collection of court case numbers and intervention applications related to constitutional interpretation and legal matters, which falls under the category of Government and Public Laws.\n",
      "\n",
      "</think>\n",
      "\n",
      "<answer>\n",
      "9. Government and Public Laws\n",
      "</answer><|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    chat = \"\"\n",
    "    \n",
    "    while True:\n",
    "        query = \"\"\"Retrieve the most informative sections of this legal document that can help determine its legal classification. Prioritize segments containing legal terms, section headings, clauses, named parties, obligations, dates, and governing laws. Specifically look for any signs related to:\n",
    "\n",
    "1. Contractual – references to B2B or B2C agreements, terms and conditions, service-level agreements, non-disclosure agreements, etc.\n",
    "2. Regulatory and Compliance – internal audit language, compliance obligations, policy enforcement, external submissions to government bodies.\n",
    "3. Intellectual Property Rights (IPR) – mentions of patents, copyrights, trademarks, trade secrets, licenses, or intellectual asset ownership.\n",
    "4. Litigation and Dispute – phrases like \"court order\", \"petition\", \"judgment\", \"arbitration\", \"claim\", or \"legal dispute\".\n",
    "5. Property and Real Estate – lease terms, ownership transfers, land records, mortgage agreements, property deeds.\n",
    "6. Corporate and Governance – company founding documents, board resolutions, shareholder agreements, filings, annual reports.\n",
    "7. Employment and HR – employment agreements, HR policies, termination letters, NDAs, resignation or separation terms.\n",
    "8. Finance and Banking – loan terms, guarantee clauses, investment contracts, collateral agreements, promissory notes.\n",
    "9. Government and Public Laws – public notices, licenses, Right to Information (RTI) references, certificates issued by authorities.\n",
    "10. Personal and Civil Legal Documents – ID proofs, marriage/divorce certificates, affidavits, inheritance documents, family law terms.\n",
    "11. Others – anything that doesn’t fit above but still contains legal relevance.\n",
    "\n",
    "Return the most relevant parts verbatim that clearly show which category the document may belong to.\n",
    "\"\"\"\n",
    "\n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Thanks for using the classifier!\")\n",
    "            break\n",
    "        similar_chunks = db.similarity_search(query, k=5)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in similar_chunks])\n",
    "        try:\n",
    "            response = model1(context=context, query=query, chat=chat, model=model, tokenizer=tokenizer,maxlen=2048)\n",
    "            # print(\"\\n[Model Output]:\\n\", response.strip(), \"\\n\")\n",
    "            chat = response\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error during inference]: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f824b685-21e5-41f0-b1bb-151c3980b36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<think>\n",
      "\n",
      "Step 1: Extracted Legal Keywords  \n",
      "[List all legal terms, phrases, and document structures found directly in the context.]\n",
      "\n",
      "- Arbitration\n",
      "- Arbitration Petition\n",
      "- Arbitrator\n",
      "- Arbitration & Conciliation Act, 1996\n",
      "- Term Sheet\n",
      "- Definitive Agreements\n",
      "- Binding contract\n",
      "- Non-binding document\n",
      "- Preamble\n",
      "- Board Resolution\n",
      "- Authorization\n",
      "- Consent\n",
      "- Conditions\n",
      "- Obligations\n",
      "- Closing obligations\n",
      "- Closing the Transaction\n",
      "- Definitive Documents\n",
      "- Clause\n",
      "- Annexure\n",
      "- Conditions precedent\n",
      "- Conditions subsequent\n",
      "- Arbitration clause\n",
      "- Section 11(6) of the Arbitration & Conciliation Act, 1996\n",
      "\n",
      "Step 2: Short Legal Summary  \n",
      "[Summarize the context in 2–3 lines using legal wording, sticking strictly to the content.]\n",
      "\n",
      "The document pertains to an arbitration proceeding between Claimants and Respondent regarding a Term Sheet dated 25.11.2015, which is disputed as to whether it is a binding or non-binding document.\n",
      "\n",
      "Step 3: Multi-Angle Rethinking  \n",
      "[Restate the summary from multiple angles: formal, casual, detailed, abstract, technical.]\n",
      "\n",
      "Formal: The document is an arbitration proceeding regarding a disputed Term Sheet.\n",
      "Casual: There's a disagreement about whether a certain document is binding or not.\n",
      "Detailed: The parties are arguing over the nature of a Term Sheet, specifically whether it's a binding contract or a non-binding exploratory document.\n",
      "Abstract: A dispute about the enforceability of a document.\n",
      "Technical: The arbitration proceeding revolves around the interpretation of a Term Sheet and its implications on the parties' obligations.\n",
      "\n",
      "Step 4: Category Matching  \n",
      "[Compare summary + keywords against each category. Write your thought process for every match or mismatch.]\n",
      "\n",
      "1. Contractual: The document discusses a Term Sheet, Definitive Agreements, and obligations, which are all contractual in nature. (Match)\n",
      "2. Regulatory and Compliance: There's a mention of the Arbitration & Conciliation Act, 1996, but it's not the primary focus of the document. (Mismatch)\n",
      "3. Intellectual Property Rights (IPR): The document mentions intellectual property rights, but it's not the main issue. (Mismatch)\n",
      "4. Litigation and Dispute: The document is an arbitration proceeding, which is a form of litigation. (Match)\n",
      "5. Property and Real Estate: There's no mention of property or real estate. (Mismatch)\n",
      "6. Corporate and Governance: The document mentions a Board Resolution, but it's not the primary focus. (Mismatch)\n",
      "7. Employment and Human Resources (HR): There's no mention of employment or HR. (Mismatch)\n",
      "8. Finance and Banking: There's no mention of finance or banking. (Mismatch)\n",
      "9. Government and Public Laws: The document mentions a statute (Arbitration & Conciliation Act, 1996), but it's not the primary focus. (Mismatch)\n",
      "10. Personal and Civil Legal Documents: The document is not personal or civil in nature. (Mismatch)\n",
      "11. Others: The document does not fit into any of the above categories. (Mismatch)\n",
      "\n",
      "Step 5: Eliminate Unrelated Categories  \n",
      "[List all categories that clearly do NOT apply and briefly explain why.]\n",
      "\n",
      "- Property and Real Estate (no mention of property or real estate)\n",
      "- Employment and Human Resources (HR) (no mention of employment or HR)\n",
      "- Finance and Banking (no mention of finance or banking)\n",
      "- Government and Public Laws (statute mentioned, but not the primary focus)\n",
      "- Personal and Civil Legal Documents (not personal or civil in nature)\n",
      "\n",
      "Step 6: Deep Legal Reasoning  \n",
      "[Based on the remaining options, explain in detail why one specific category is the strongest fit using legal logic.]\n",
      "\n",
      "The document is an arbitration proceeding, which is a form of litigation. The parties are disputing the nature of a Term Sheet, which is a contractual document. The document discusses obligations, conditions, and the enforceability of the Term Sheet, all of which are contractual in nature. The arbitration proceeding is focused on resolving the dispute between the parties regarding the Term Sheet, which is a contractual document. Therefore, the strongest fit is the Litigation and Dispute category.\n",
      "\n",
      "Step 7: Final Justification  \n",
      "[Final 1-2 lines defending your classification using exact phrases or structure from the context.]\n",
      "\n",
      "The document is an arbitration proceeding, which is a form of litigation, and the parties are disputing the nature of a Term Sheet, which is a contractual document. The arbitration proceeding is focused on resolving the dispute between the parties regarding the Term Sheet, which is a contractual document.\n",
      "\n",
      "<answer>\n",
      "1. Litigation and Dispute<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    chat = \"\"\n",
    "    \n",
    "    while True:\n",
    "        query = \"\"\"Retrieve the most informative sections of this legal document that can help determine its legal classification. Prioritize segments containing legal terms, section headings, clauses, named parties, obligations, dates, and governing laws. Specifically look for any signs related to:\n",
    "\n",
    "1. Contractual – references to B2B or B2C agreements, terms and conditions, service-level agreements, non-disclosure agreements, etc.\n",
    "2. Regulatory and Compliance – internal audit language, compliance obligations, policy enforcement, external submissions to government bodies.\n",
    "3. Intellectual Property Rights (IPR) – mentions of patents, copyrights, trademarks, trade secrets, licenses, or intellectual asset ownership.\n",
    "4. Litigation and Dispute – phrases like \"court order\", \"petition\", \"judgment\", \"arbitration\", \"claim\", or \"legal dispute\".\n",
    "5. Property and Real Estate – lease terms, ownership transfers, land records, mortgage agreements, property deeds.\n",
    "6. Corporate and Governance – company founding documents, board resolutions, shareholder agreements, filings, annual reports.\n",
    "7. Employment and HR – employment agreements, HR policies, termination letters, NDAs, resignation or separation terms.\n",
    "8. Finance and Banking – loan terms, guarantee clauses, investment contracts, collateral agreements, promissory notes.\n",
    "9. Government and Public Laws – public notices, licenses, Right to Information (RTI) references, certificates issued by authorities.\n",
    "10. Personal and Civil Legal Documents – ID proofs, marriage/divorce certificates, affidavits, inheritance documents, family law terms.\n",
    "11. Others – anything that doesn’t fit above but still contains legal relevance.\n",
    "\n",
    "Return the most relevant parts verbatim that clearly show which category the document may belong to.\n",
    "\"\"\"\n",
    "\n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Thanks for using the classifier!\")\n",
    "            break\n",
    "        similar_chunks = db.similarity_search(query, k=5)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in similar_chunks])\n",
    "        try:\n",
    "            response = model1(context=context, query=query, chat=chat, model=model, tokenizer=tokenizer,maxlen=2048)\n",
    "            # print(\"\\n[Model Output]:\\n\", response.strip(), \"\\n\")\n",
    "            chat = response\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error during inference]: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e47afc2c-6df2-4e27-8b3c-a24b933fb5bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<think>\n",
      "\n",
      "Step 1: Extracted Legal Keywords  \n",
      "[List all legal terms, phrases, and document structures found directly in the context.]\n",
      "\n",
      "- License\n",
      "- Agreement\n",
      "- Representations and Warranties\n",
      "- Limitations of Liability\n",
      "- Disclaimer\n",
      "- Indemnification\n",
      "- Force Majeure\n",
      "- Governing Law and Forum\n",
      "- Assignment\n",
      "- Severability\n",
      "- Waiver\n",
      "- Termination\n",
      "- Notice\n",
      "- Consent\n",
      "- Assignment\n",
      "- Sale\n",
      "- Merger\n",
      "- Business Combination\n",
      "- Liquidation\n",
      "- Trustee\n",
      "- Receiver\n",
      "- Jurisdiction\n",
      "- Venue\n",
      "- Arbitration\n",
      "- Injunction\n",
      "- Damages\n",
      "- Breach\n",
      "- Contract\n",
      "- Obligation\n",
      "- Enforceability\n",
      "- Validity\n",
      "- Intellectual Property\n",
      "- Trademark\n",
      "- Copyright\n",
      "- Patent\n",
      "- Right of Privacy\n",
      "- Defamation\n",
      "- Exclusivity\n",
      "- Jurisdiction\n",
      "- Venue\n",
      "- Governing Law\n",
      "\n",
      "Step 2: Short Legal Summary  \n",
      "[Summarize the context in 2–3 lines using legal wording, sticking strictly to the content.]\n",
      "\n",
      "This document is an agreement between Zynga Inc. and Allied Esports Entertainment, Inc. regarding the licensing of intellectual property. The agreement outlines the terms and conditions of the license, including representations and warranties, limitations of liability, and termination clauses.\n",
      "\n",
      "Step 3: Multi-Angle Rethinking  \n",
      "[Restate the summary from multiple angles: formal, casual, detailed, abstract, technical.]\n",
      "\n",
      "Formal: This document is a contractual agreement between two parties regarding intellectual property licensing.\n",
      "Casual: It's a contract between Zynga and Allied Esports about using their brand and stuff.\n",
      "Detailed: The agreement outlines the terms and conditions of the license, including representations and warranties, limitations of liability, and termination clauses.\n",
      "Abstract: A licensing agreement between two parties.\n",
      "Technical: This document is a legally binding contract between Zynga Inc. and Allied Esports Entertainment, Inc. regarding the licensing of intellectual property, including representations and warranties, limitations of liability, and termination clauses.\n",
      "\n",
      "Step 4: Category Matching  \n",
      "[Compare summary + keywords against each category. Write your thought process for every match or mismatch.]\n",
      "\n",
      "1. Contractual: This category seems to be a strong fit because the document is an agreement between two parties regarding the licensing of intellectual property.\n",
      "2. Regulatory and Compliance: There are some regulatory terms, but they are not the primary focus of the document.\n",
      "3. Intellectual Property Rights (IPR): The document does deal with intellectual property, but it's more about licensing than ownership or rights.\n",
      "4. Litigation and Dispute: There are some clauses about termination and breach, but it's not primarily a dispute resolution document.\n",
      "5. Property and Real Estate: Not applicable, as the document is about intellectual property, not physical property.\n",
      "6. Corporate and Governance: Some corporate terms are present, but it's not primarily about corporate governance.\n",
      "7. Employment and Human Resources (HR): Not applicable, as the document is not about employment or HR.\n",
      "8. Finance and Banking: There are some financial terms, but it's not primarily about finance or banking.\n",
      "9. Government and Public Laws: Some regulatory terms are present, but it's not primarily about government or public laws.\n",
      "10. Personal and Civil Legal Documents: Not applicable, as the document is not about personal or civil matters.\n",
      "11. Others: Not applicable, as the document fits into one of the above categories.\n",
      "\n",
      "Step 5: Eliminate Unrelated Categories  \n",
      "[List all categories that clearly do NOT apply and briefly explain why.]\n",
      "\n",
      "- Property and Real Estate: The document is about intellectual property, not physical property.\n",
      "- Employment and Human Resources (HR): The document is not about employment or HR.\n",
      "- Finance and Banking: The document is not primarily about finance or banking.\n",
      "- Government and Public Laws: The document is not primarily about government or public laws.\n",
      "- Personal and Civil Legal Documents: The document is not about personal or civil matters.\n",
      "\n",
      "Step 6: Deep Legal Reasoning  \n",
      "[Based on the remaining options, explain in detail why one specific category is the strongest fit using legal logic.]\n",
      "\n",
      "The strongest fit is the Contractual category. The document is an agreement between two parties, outlining the terms and conditions of the license, including representations and warranties, limitations of liability, and termination clauses. The language used is formal and binding, indicating a contractual relationship. The document also contains clauses about consent, notice, and assignment, which are typical of contractual agreements. Furthermore, the document is a legally binding contract, which is a fundamental concept in contract law.\n",
      "\n",
      "Step 7: Final Justification  \n",
      "[Final 1-2 lines defending your classification using exact phrases or structure from the context.]\n",
      "\n",
      "This document is a contractual agreement between Zynga Inc. and Allied Esports Entertainment, Inc. regarding the licensing of intellectual property, as evident from the language used in the \"AGREEMENT\" section and the \"REPRESENTATIONS AND WARRANTIES\" clause.\n",
      "\n",
      "<answer>\n",
      "1. Contractual<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    chat = \"\"\n",
    "    \n",
    "    while True:\n",
    "        query = \"\"\"Retrieve the most informative sections of this legal document that can help determine its legal classification. Prioritize segments containing legal terms, section headings, clauses, named parties, obligations, dates, and governing laws. Specifically look for any signs related to:\n",
    "\n",
    "1. Contractual – references to B2B or B2C agreements, terms and conditions, service-level agreements, non-disclosure agreements, etc.\n",
    "2. Regulatory and Compliance – internal audit language, compliance obligations, policy enforcement, external submissions to government bodies.\n",
    "3. Intellectual Property Rights (IPR) – mentions of patents, copyrights, trademarks, trade secrets, licenses, or intellectual asset ownership.\n",
    "4. Litigation and Dispute – phrases like \"court order\", \"petition\", \"judgment\", \"arbitration\", \"claim\", or \"legal dispute\".\n",
    "5. Property and Real Estate – lease terms, ownership transfers, land records, mortgage agreements, property deeds.\n",
    "6. Corporate and Governance – company founding documents, board resolutions, shareholder agreements, filings, annual reports.\n",
    "7. Employment and HR – employment agreements, HR policies, termination letters, NDAs, resignation or separation terms.\n",
    "8. Finance and Banking – loan terms, guarantee clauses, investment contracts, collateral agreements, promissory notes.\n",
    "9. Government and Public Laws – public notices, licenses, Right to Information (RTI) references, certificates issued by authorities.\n",
    "10. Personal and Civil Legal Documents – ID proofs, marriage/divorce certificates, affidavits, inheritance documents, family law terms.\n",
    "11. Others – anything that doesn’t fit above but still contains legal relevance.\n",
    "\n",
    "Return the most relevant parts verbatim that clearly show which category the document may belong to.\n",
    "\"\"\"\n",
    "\n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Thanks for using the classifier!\")\n",
    "            break\n",
    "        similar_chunks = db.similarity_search(query, k=5)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in similar_chunks])\n",
    "        try:\n",
    "            response = model1(context=context, query=query, chat=chat, model=model, tokenizer=tokenizer,maxlen=2048)\n",
    "            # print(\"\\n[Model Output]:\\n\", response.strip(), \"\\n\")\n",
    "            chat = response\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error during inference]: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6d7300-b60d-401a-9bf1-edc71e0f1c46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<think>\n",
      "\n",
      "Step 1: Extracted Legal Keywords  \n",
      "[List all legal terms, phrases, and document structures found directly in the context.]\n",
      "\n",
      "* Petitioners\n",
      "* Respondent\n",
      "* Writ Petition\n",
      "* Coram\n",
      "* Hon'ble Mr. Justice\n",
      "* Judgment (Oral)\n",
      "* Release Medical Board (RMB)\n",
      "* Disability Pension\n",
      "* Entitlement Rules\n",
      "* Supreme Court\n",
      "* Tribunal\n",
      "* AFT (Armed Forces Tribunal)\n",
      "* Onus\n",
      "* Claimant\n",
      "* Military Service\n",
      "* Medical Category\n",
      "* Low Medical Category A4 G2(P)\n",
      "* Hypertension\n",
      "* Primary Hypertension\n",
      "* Medical Board Report\n",
      "* Personal Statement\n",
      "* Commanding Officer\n",
      "* Part-III of the RMB Report\n",
      "* Field/HAA or CIOPS / Active operation area\n",
      "* AFT (Armed Forces Tribunal)\n",
      "* Entitlement Rules\n",
      "* Supreme Court\n",
      "* RMB (Release Medical Board)\n",
      "* RMB Report\n",
      "* Medical Category\n",
      "* Low Medical Category A4 G2(P)\n",
      "* Hypertension\n",
      "* Primary Hypertension\n",
      "* Medical Board Report\n",
      "* Personal Statement\n",
      "* Commanding Officer\n",
      "* Part-III of the RMB Report\n",
      "* Field/HAA or CIOPS / Active operation area\n",
      "\n",
      "Step 2: Short Legal Summary  \n",
      "[Summarize the context in 2–3 lines using legal wording, sticking strictly to the content.]\n",
      "\n",
      "The Union of India vs Ex HFO Patil Rajkumar Dhansingh is a case regarding the entitlement to disability pension for hypertension. The respondent, a former Air Force officer, was diagnosed with primary hypertension after 34 years of service and was superannuated. The Release Medical Board (RMB) opined that the hypertension was not attributable to military service.\n",
      "\n",
      "Step 3: Multi-Angle Rethinking  \n",
      "[Restate the summary from multiple angles: formal, casual, detailed, abstract, technical.]\n",
      "\n",
      "Formal: The case concerns the entitlement to disability pension for hypertension in the context of military service.\n",
      "\n",
      "Casual: A former Air Force officer is fighting for disability pension due to hypertension, but the medical board says it's not related to his service.\n",
      "\n",
      "Detailed: The case revolves around the interpretation of the entitlement rules regarding disability pension for hypertension, with the respondent arguing that his 34 years of military service should be considered in determining the attributability of the condition.\n",
      "\n",
      "Abstract: A dispute over disability pension for hypertension in the military context.\n",
      "\n",
      "Technical: The case involves the application of the entitlement rules, specifically Rule 75 of the 2008 Entitlement Rules, to determine the attributability of hypertension to military service.\n",
      "\n",
      "Step 4: Category Matching  \n",
      "[Compare summary + keywords against each category. Write your thought process for every match or mismatch.]\n",
      "\n",
      "* Contractual: No direct match, as the document is not related to agreements or contracts.\n",
      "* Regulatory and Compliance: Possible match, as the document involves the interpretation of entitlement rules and medical board reports.\n",
      "* Intellectual Property Rights (IPR): No match, as the document does not involve intellectual property rights.\n",
      "* Litigation and Dispute: Strong match, as the document is a court judgment in a dispute over disability pension.\n",
      "* Property and Real Estate: No match, as the document does not involve property or real estate.\n",
      "* Corporate and Governance: No match, as the document is not related to company formation or governance.\n",
      "* Employment and Human Resources (HR): Possible match, as the document involves a former employee's entitlement to disability pension.\n",
      "* Finance and Banking: No match, as the document is not related to financial transactions or banking.\n",
      "* Government and Public Laws: Strong match, as the document involves the interpretation of government rules and regulations.\n",
      "* Personal and Civil Legal Documents: Possible match, as the document involves a personal dispute over disability pension.\n",
      "* Others: No match, as the document does not fit into any other category.\n",
      "\n",
      "Step 5: Eliminate Unrelated Categories  \n",
      "[List all categories that clearly do NOT apply and briefly explain why.]\n",
      "\n",
      "* Contractual: Not applicable, as the document is not related to agreements or contracts.\n",
      "* Property and Real Estate: Not applicable, as the document does not involve property or real estate.\n",
      "* Corporate and Governance: Not applicable, as the document is not related to company formation or governance.\n",
      "* Finance and Banking: Not applicable, as the document is not related to financial transactions or banking.\n",
      "* Others: Not applicable, as the document fits into one of the other categories.\n",
      "\n",
      "Step 6: Deep Legal Reasoning  \n",
      "[Based on the remaining options, explain in detail why one specific category is the strongest fit using legal logic.]\n",
      "\n",
      "The strongest fit for the document is Litigation and Dispute, as it is a court judgment in a dispute over disability pension. The document involves the interpretation of government rules and regulations, specifically the entitlement rules, and the application of the law to determine the attributability of hypertension to military service. The language used in the document, such as \"writ petition,\" \"coram,\" and \"judgment (oral),\" is also consistent with a court judgment.\n",
      "\n",
      "Step 7: Final Justification  \n",
      "[Final 1-2 lines defending your classification using exact phrases or structure from the context.]\n",
      "\n",
      "The document is a \"writ petition\" (Step 7) and a \"judgment (oral)\" (Step 7) in a dispute over disability pension, which makes Litigation and Dispute the strongest fit.\n",
      "\n",
      "<answer>\n",
      "4. Litigation and Dispute<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    chat = \"\"\n",
    "    \n",
    "    while True:\n",
    "        query = \"\"\"Retrieve the most informative sections of this legal document that can help determine its legal classification. Prioritize segments containing legal terms, section headings, clauses, named parties, obligations, dates, and governing laws. Specifically look for any signs related to:\n",
    "\n",
    "1. Contractual – references to B2B or B2C agreements, terms and conditions, service-level agreements, non-disclosure agreements, etc.\n",
    "2. Regulatory and Compliance – internal audit language, compliance obligations, policy enforcement, external submissions to government bodies.\n",
    "3. Intellectual Property Rights (IPR) – mentions of patents, copyrights, trademarks, trade secrets, licenses, or intellectual asset ownership.\n",
    "4. Litigation and Dispute – phrases like \"court order\", \"petition\", \"judgment\", \"arbitration\", \"claim\", or \"legal dispute\".\n",
    "5. Property and Real Estate – lease terms, ownership transfers, land records, mortgage agreements, property deeds.\n",
    "6. Corporate and Governance – company founding documents, board resolutions, shareholder agreements, filings, annual reports.\n",
    "7. Employment and HR – employment agreements, HR policies, termination letters, NDAs, resignation or separation terms.\n",
    "8. Finance and Banking – loan terms, guarantee clauses, investment contracts, collateral agreements, promissory notes.\n",
    "9. Government and Public Laws – public notices, licenses, Right to Information (RTI) references, certificates issued by authorities.\n",
    "10. Personal and Civil Legal Documents – ID proofs, marriage/divorce certificates, affidavits, inheritance documents, family law terms.\n",
    "11. Others – anything that doesn’t fit above but still contains legal relevance.\n",
    "\n",
    "Return the most relevant parts verbatim that clearly show which category the document may belong to.\n",
    "\"\"\"\n",
    "\n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Thanks for using the classifier!\")\n",
    "            break\n",
    "        similar_chunks = db.similarity_search(query, k=5)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in similar_chunks])\n",
    "        try:\n",
    "            response = model1(context=context, query=query, chat=chat, model=model, tokenizer=tokenizer,maxlen=2048)\n",
    "            # print(\"\\n[Model Output]:\\n\", response.strip(), \"\\n\")\n",
    "            chat = response\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error during inference]: {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e371d2fc-d436-4993-854e-05764b5a7a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98792b37-f382-4308-b926-bfbe06176c83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Further Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5957a274-ae96-43ff-a0b0-2f12338b533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFacePipeline\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM,BitsAndBytesConfig,StoppingCriteria, StoppingCriteriaList\n",
    "import torch\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db80b862-8ab7-46ac-bf6e-83f3c6c3b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stream(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, stop_token_id=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stop_token_id = stop_token_id\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        new_token_id = input_ids[0, -1].item()\n",
    "        if self.stop_token_id is not None and new_token_id == self.stop_token_id:\n",
    "            return True\n",
    "        token_text = self.tokenizer.decode([new_token_id], skip_special_tokens=False)\n",
    "        print(token_text, end=\"\", flush=True)\n",
    "        return False\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def loading_pdf(path=\"/home/pa2/ml/Document-Classification/files/1_D:\\BPL\\BLS\\Document\\Arbitration Award of Zostel Hospitality relied upon by the Claimant.txt\"):\n",
    "    \"\"\"Loads a text file and splits it into chunks.\"\"\"\n",
    "    loader = TextLoader(path, encoding=\"utf-8\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    \n",
    "    return docs\n",
    "    \n",
    "def faiss1(docs):\n",
    "    model=HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "    )\n",
    "    db=FAISS.from_documents(docs,model)\n",
    "    return db\n",
    "def model1(context,query,chat,model,tokenizer,maxlen=3000):\n",
    "    \n",
    "    message = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"You are a legal assistant trained to classify legal documents with zero tolerance for guessing. You must follow the rules below strictly:\n",
    "\n",
    "RULES:\n",
    "1. Do NOT make assumptions or use external knowledge.\n",
    "2. ONLY use exact words, legal terms, and structures from the given context.\n",
    "3. You MUST explain your classification using legal terminology from the context.\n",
    "4. You MUST follow the exact output format below.\n",
    "5. Return one and only one category from the list below.\n",
    "\n",
    "LEGAL CATEGORIES with EXAMPLES:\n",
    "\n",
    "1. Contractual – (e.g., B2B agreements, purchase orders, NDAs, service contracts)  \n",
    "2. Regulatory and Compliance – (e.g., compliance reports, internal audits, regulatory filings)  \n",
    "3. Intellectual Property Rights (IPR) – (e.g., patents, trademarks, copyrights, design rights, trade secrets)  \n",
    "4. Litigation and Dispute – (e.g., court filings, legal notices, arbitration claims, judgments)  \n",
    "5. Property and Real Estate – (e.g., lease agreements, sale deeds, land registration, rent contracts)  \n",
    "6. Corporate and Governance – (e.g., company formation docs, resolutions, board meeting records, annual filings)  \n",
    "7. Employment and Human Resources (HR) – (e.g., employee contracts, HR policies, separation letters)  \n",
    "8. Finance and Banking – (e.g., loan agreements, collateral deeds, investment deals, bank guarantees)  \n",
    "9. Government and Public Laws – (e.g., RTI responses, government licenses, public notices, certificates)  \n",
    "10. Personal and Civil Legal Documents – (e.g., ID proofs, affidavits, marriage/divorce documents, family law papers)  \n",
    "11. Others – (Only if no other category fits)\n",
    "\n",
    "\n",
    "---\n",
    "MANDATORY RULE MUST FOLLOW :-\n",
    "-> **PROPERLY SHOW ALL THE STEPS IN <think> SECTION** (MANDATORY)\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "---\n",
    "\n",
    "<think>Steps\n",
    "\n",
    "Step 1: Extracted Legal Keywords →  \n",
    "[List all legal terms, phrases, and document structures found directly in the context.]\n",
    "\n",
    "Step 2: Short Legal Summary →  \n",
    "[Summarize the context in 2–3 lines using legal wording, sticking strictly to the content.]\n",
    "\n",
    "Step 3: Multi-Angle Rethinking →  \n",
    "[Restate the summary from multiple angles: formal, casual, detailed, abstract, technical.]\n",
    "\n",
    "Step 4: Category Matching →  \n",
    "[Compare summary + keywords against each category. Write your thought process for every match or mismatch.]\n",
    "\n",
    "Step 5: Eliminate Unrelated Categories →  \n",
    "[List all categories that clearly do NOT apply and briefly explain why.]\n",
    "\n",
    "Step 6: Deep Legal Reasoning →  \n",
    "[Based on the remaining options, explain in detail why one specific category is the strongest fit using legal logic.]\n",
    "\n",
    "Step 7: Final Justification →  \n",
    "[Final 1-2 lines defending your classification using exact phrases or structure from the context.]\n",
    "\n",
    "Step 8: Sub-Category Identification →\n",
    "Refer to the legal sub-category hierarchy provided. Using the keywords, structure, and context of the document:\n",
    "\n",
    "→ If confidently matched: Identify the sub-category under the selected main category (e.g., Contractual → General Commercial Contracts → Sales Agreements).\n",
    "→ If only the second level (e.g., General Commercial Contracts) is confidently identifiable and not the third level (e.g., Sales Agreements), stop at the second level.\n",
    "→ If sub-categorization is ambiguous or inconsistent with the context, return only the main category determined in Step 7.\n",
    "\n",
    "Write your analysis as follows:\n",
    "• Sub-Category Options Considered: [List possible sub-categories under the selected main category]\n",
    "• Reasoning for Chosen Sub-Category (if any): [Use legal terms and document structure from context + .txt reference]\n",
    "• Final Sub-Category Classification (max depth = 3 levels): [Write final classification path OR stop at level 2 if unsure]\n",
    "\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "Choose ONLY ONE from this list (copy-paste one line only):\n",
    "\n",
    "1. Contractual  \n",
    "2. Regulatory and Compliance  \n",
    "3. Intellectual Property Rights (IPR)  \n",
    "4. Litigation and Dispute  \n",
    "5. Property and Real Estate  \n",
    "6. Corporate and Governance  \n",
    "7. Employment and Human Resources (HR)  \n",
    "8. Finance and Banking  \n",
    "9. Government and Public Laws  \n",
    "10. Personal and Civil Legal Documents  \n",
    "11. Others\n",
    "</answer>\n",
    "\n",
    "\n",
    "Question: What is the correct legal category for this document?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    }]\n",
    "\n",
    "    prompt=tokenizer.apply_chat_template(message,tokenize=False)\n",
    "    input_ids=tokenizer(prompt,return_tensors='pt').to(\"cuda\")\n",
    "    stopping_criteria = StoppingCriteriaList([Stream(tokenizer)])\n",
    "    with torch.no_grad():\n",
    "        response=model.generate(input_ids=input_ids['input_ids'],\n",
    "                                attention_mask=input_ids['attention_mask'],\n",
    "                                stopping_criteria=stopping_criteria,\n",
    "                                max_new_tokens=maxlen,\n",
    "                                use_cache=True,\n",
    "                               temperature=0.1,)\n",
    "    answer=tokenizer.decode(response[0])\n",
    "    print()\n",
    "    return answer\n",
    "\n",
    "def model2(context,query,chat,model,tokenizer,maxlen=3000):\n",
    "    \n",
    "    message = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"You are a legal assistant trained to classify legal documents with zero tolerance for guessing. You must follow the rules below strictly:\n",
    "\n",
    "RULES:\n",
    "1. Do NOT make assumptions or use external knowledge.\n",
    "2. ONLY use exact words, legal terms, and structures from the given context.\n",
    "3. You MUST explain your classification using legal terminology from the context.\n",
    "4. You MUST follow the exact output format below.\n",
    "5. Return one and only one category from the list below.\n",
    "\n",
    "LEGAL CATEGORIES with EXAMPLES:\n",
    "{query}\n",
    "\n",
    "\n",
    "---\n",
    "MANDATORY RULE MUST FOLLOW :-\n",
    "-> **PROPERLY SHOW ALL THE STEPS IN <think> SECTION** (MANDATORY)\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "---\n",
    "\n",
    "<think>Steps\n",
    "\n",
    "Step 1: Extracted Legal Keywords →  \n",
    "[List all legal terms, phrases, and document structures found directly in the context.]\n",
    "\n",
    "Step 2: Short Legal Summary →  \n",
    "[Summarize the context in 2–3 lines using legal wording, sticking strictly to the content.]\n",
    "\n",
    "Step 4: SUB Category Matching →  \n",
    "[Compare summary + keywords against each category. Write your thought process for every match or mismatch.]\n",
    "\n",
    "Step 5: Eliminate Unrelated SUB Categories →  \n",
    "[List all categories that clearly do NOT apply and briefly explain why.]\n",
    "\n",
    "Step 6: Deep Legal Reasoning →  \n",
    "[Based on the remaining options, explain in detail why one specific sub category is the strongest fit using legal logic.]\n",
    "\n",
    "Step 7: Final Justification →  \n",
    "[Final 1-2 lines defending your classification using exact phrases or structure from the context.]\n",
    "\n",
    "\n",
    "</think>\n",
    "\n",
    "<answer>\n",
    "(whatever is the best matched category)\n",
    "</answer>\n",
    "\n",
    "\n",
    "Question: What is the correct legal category for this document?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    }]\n",
    "\n",
    "    prompt=tokenizer.apply_chat_template(message,tokenize=False)\n",
    "    input_ids=tokenizer(prompt,return_tensors='pt').to(\"cuda\")\n",
    "    stopping_criteria = StoppingCriteriaList([Stream(tokenizer)])\n",
    "    with torch.no_grad():\n",
    "        response=model.generate(input_ids=input_ids['input_ids'],\n",
    "                                attention_mask=input_ids['attention_mask'],\n",
    "                                stopping_criteria=stopping_criteria,\n",
    "                                max_new_tokens=maxlen,\n",
    "                                use_cache=True,\n",
    "                               temperature=0.1,)\n",
    "    answer=tokenizer.decode(response[0])\n",
    "    print()\n",
    "    return answer\n",
    "\n",
    "def loading_pdf1(path):\n",
    "    \"\"\"Loads a PDF or text file and splits it into chunks.\"\"\"\n",
    "    if path.endswith(\".txt\"):\n",
    "        loader = TextLoader(path, encoding=\"utf-8\")\n",
    "    elif path.lower().endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Only .txt and .pdf are supported.\")\n",
    "\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    return docs\n",
    "# docs=loading_pdf()\n",
    "docs=loading_pdf1(\"/home/pa2/ml/Document-Classification/files/Section_12_in_The_Contempt_Of_Courts_Act_1971.PDF\")\n",
    "db=faiss1(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f85e72-3805-489e-8ea5-9544dbae7012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f2d5ab456949948ad636f3b7e51275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# Specify how much memory can be used by GPU and CPU\n",
    "max_memory = {\n",
    "    0: \"7GiB\",     # GPU 0 — use an integer instead of \"cuda:0\"\n",
    "    \"cpu\": \"30GiB\"\n",
    "}\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",  # Huggingface will decide based on max_memory\n",
    "    max_memory=max_memory,\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f459010-8c7c-4891-9440-0ad2a250cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_address(response):\n",
    "    if \"<answer>1. Contractual<|eot_id|>\" in response:\n",
    "        return 1\n",
    "    elif \"<answer>2. Regulatory and Compliance<|eot_id|>\" in response:\n",
    "        return 2\n",
    "    elif \"<answer>3. Intellectual Property Rights (IPR)<|eot_id|>\" in response:\n",
    "        return 3\n",
    "    elif \"<answer>4. Litigation and Dispute<|eot_id|>\" in response:\n",
    "        return 4\n",
    "    elif \"<answer>5. Property and Real Estate<|eot_id|>\":\n",
    "        return 5\n",
    "    elif \"<answer>6. Corporate and Governance<|eot_id|>\":\n",
    "        return 6\n",
    "    elif \"<answer>7. Employment and HR<|eot_id|>\":\n",
    "        return 7\n",
    "    elif \"<answer>8. Finance and Banking<|eot_id|>\":\n",
    "        return 8\n",
    "    elif \"<answer>9. Government and Public Laws<|eot_id|>\":\n",
    "        return 9\n",
    "    elif \"<answer>10. Personal and Civil Legal Documents<|eot_id|>\":\n",
    "        return 10\n",
    "    else:\n",
    "        return 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3248adb2-34aa-469b-9c79-577fd92c1c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<think>\n",
      "\n",
      "Step 1: Extracted Legal Keywords  \n",
      "[Legal terms, phrases, and document structures found directly in the context: contempt of court, contempt, punishment, imprisonment, fine, civil contempt, civil prison, company, director, manager, secretary, officer, contempt of court, undertaking, guilty, apology, qualified or conditional apology, civil prison, detention, contempt of court, civil contempt, contempt of court, contempt of court, contempt of court.]\n",
      "\n",
      "Step 2: Short Legal Summary  \n",
      "[The document discusses the punishment for contempt of court under the Contempt of Courts Act, 1971, outlining the imprisonment and fine for contempt, and the liability of companies and their officers for contempt committed by them.]\n",
      "\n",
      "Step 3: Multi-Angle Rethinking  \n",
      "[Formal: The document outlines the legal consequences of contempt of court. Casual: It's about getting in trouble with the law for disrespecting the court. Detailed: The document specifies the punishments for contempt, including imprisonment and fines, and the liability of companies and their officers. Abstract: The document deals with the concept of contempt of court and its legal implications. Technical: The document outlines the legal framework for punishing contempt of court under the Contempt of Courts Act, 1971.]\n",
      "\n",
      "Step 4: Category Matching  \n",
      "[Comparing summary + keywords against each category.]\n",
      "\n",
      "1. Contractual: No direct match, as the document is not about agreements or contracts.\n",
      "2. Regulatory and Compliance: Possible match, as the document deals with the legal framework for punishing contempt of court.\n",
      "3. Intellectual Property Rights (IPR): No direct match, as the document does not deal with patents, trademarks, copyrights, or other IPR issues.\n",
      "4. Litigation and Dispute: Possible match, as the document deals with the consequences of contempt of court, which can lead to litigation.\n",
      "5. Property and Real Estate: No direct match, as the document does not deal with property or real estate issues.\n",
      "6. Corporate and Governance: Possible match, as the document deals with the liability of companies and their officers for contempt committed by them.\n",
      "7. Employment and Human Resources (HR): No direct match, as the document does not deal with employment or HR issues.\n",
      "8. Finance and Banking: No direct match, as the document does not deal with financial or banking issues.\n",
      "9. Government and Public Laws: Possible match, as the document deals with the legal framework for punishing contempt of court under a government law.\n",
      "10. Personal and Civil Legal Documents: Possible match, as the document deals with the consequences of contempt of court, which can affect individuals.\n",
      "11. Others: No match, as the document fits into one of the above categories.\n",
      "\n",
      "Step 5: Eliminate Unrelated Categories  \n",
      "[Categories that clearly do NOT apply.]\n",
      "\n",
      "* Contractual\n",
      "* Intellectual Property Rights (IPR)\n",
      "* Property and Real Estate\n",
      "* Employment and Human Resources (HR)\n",
      "* Finance and Banking\n",
      "\n",
      "Step 6: Deep Legal Reasoning  \n",
      "[Based on the remaining options, explain in detail why one specific category is the strongest fit using legal logic.]\n",
      "\n",
      "The document deals with the legal framework for punishing contempt of court, which is a government law. The Contempt of Courts Act, 1971, is a regulatory law that outlines the consequences of contempt of court. Therefore, the strongest fit is Regulatory and Compliance.\n",
      "\n",
      "Step 7: Final Justification  \n",
      "[Final 1-2 lines defending your classification using exact phrases or structure from the context.]\n",
      "\n",
      "The document is classified under Regulatory and Compliance as it deals with the legal framework for punishing contempt of court under the Contempt of Courts Act, 1971.\n",
      "\n",
      "Step 8: Sub-Category Identification  \n",
      "[Sub-category under the selected main category.]\n",
      "\n",
      "• Sub-Category Options Considered: Government Laws and Regulations\n",
      "• Reasoning for Chosen Sub-Category: The document deals with the legal framework for punishing contempt of court under a government law, specifically the Contempt of Courts Act, 1971.\n",
      "• Final Sub-Category Classification: Regulatory and Compliance → Government Laws and Regulations\n",
      "\n",
      "<answer>\n",
      "2. Regulatory and Compliance<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    address={\n",
    "        1:\"ml/Document-Classification/1.Contractual Document Sub Categories.txt\",\n",
    "        2:\"ml/Document-Classification/2.Regulatory and Compliance Sub Categories.txt\",\n",
    "        3:\"ml/Document-Classification/3.IPR Categories.txt\",\n",
    "        4:\"ml/Document-Classification/4.Litigation and Dispute Categories.txt\",\n",
    "        5:\"ml/Document-Classification/5.Property and Real Estate.txt\",\n",
    "        6:\"ml/Document-Classification/6.Corporate and Governance Categories.txt\",\n",
    "        7:\"ml/Document-Classification/7.HR Document categories.txt\",\n",
    "        8:\"ml/Document-Classification/8.Finance and Banking Categories.txt\",\n",
    "        9:\"ml/Document-Classification/9.Government and public laws.txt\",\n",
    "        10:\"ml/Document-Classification/10.Personal and Civil Legal Documents.txt\"\n",
    "    }\n",
    "\n",
    "    query = \"\"\"Retrieve the most informative sections of this legal document that can help determine its legal classification. Prioritize segments containing legal terms, section headings, clauses, named parties, obligations, dates, and governing laws. Specifically look for any signs related to:\n",
    "\n",
    "1. Contractual – references to B2B or B2C agreements, terms and conditions, service-level agreements, non-disclosure agreements, etc.\n",
    "2. Regulatory and Compliance – internal audit language, compliance obligations, policy enforcement, external submissions to government bodies.\n",
    "3. Intellectual Property Rights (IPR) – mentions of patents, copyrights, trademarks, trade secrets, licenses, or intellectual asset ownership.\n",
    "4. Litigation and Dispute – phrases like \"court order\", \"petition\", \"judgment\", \"arbitration\", \"claim\", or \"legal dispute\".\n",
    "5. Property and Real Estate – lease terms, ownership transfers, land records, mortgage agreements, property deeds.\n",
    "6. Corporate and Governance – company founding documents, board resolutions, shareholder agreements, filings, annual reports.\n",
    "7. Employment and HR – employment agreements, HR policies, termination letters, NDAs, resignation or separation terms.\n",
    "8. Finance and Banking – loan terms, guarantee clauses, investment contracts, collateral agreements, promissory notes.\n",
    "9. Government and Public Laws – public notices, licenses, Right to Information (RTI) references, certificates issued by authorities.\n",
    "10. Personal and Civil Legal Documents – ID proofs, marriage/divorce certificates, affidavits, inheritance documents, family law terms.\n",
    "11. Others – anything that doesn’t fit above but still contains legal relevance.\n",
    "\n",
    "Return the most relevant parts verbatim that clearly show which category the document may belong to.\n",
    "\"\"\"\n",
    "    chat=\"\"\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Thanks for using the classifier!\")\n",
    "    similar_chunks = db.similarity_search(query, k=3)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in similar_chunks])\n",
    "    try:\n",
    "        response = model1(context=context, query=query, chat=chat, model=model, tokenizer=tokenizer,maxlen=2048)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Error during inference]: {e}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    # key=txt_address(response)\n",
    "    # if key!=11:\n",
    "    #     with open(address[key], \"r\", encoding=\"utf-8\") as file:\n",
    "    #         new_context = file.read()\n",
    "    #     response1 = model2(context=context, query=new_context, chat=chat, model=model, tokenizer=tokenizer,maxlen=2048)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7a88b-4095-4285-9e79-70288721612e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
